{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"c2-TF2-Entrenar-Modelo-Simbolos.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pHefTSRioYTI"},"source":["# Realiza el Entrenamiento del Modelo para Detección de los Operadores de un Cursograma usando los modelos provistos por TensorFlow versión 2\n","\n","Fuentes:\n","\n","- original con TF1 -> https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/\n","\n","- nuevo para TF2 -> https://towardsdatascience.com/how-to-train-a-tensorflow-2-object-detection-model-25d4da64b817 +  https://colab.research.google.com/drive/1sLqFKVV94wm-lglFq_0kGo2ciM0kecWD#scrollTo=fF8ysCfYKgTP&uniqifier=1\n"]},{"cell_type":"markdown","metadata":{"id":"jKsjtRyL56Zm"},"source":["1) Preparar el ambiente: "]},{"cell_type":"code","metadata":{"id":"N_IFR3NUeP5F","cellView":"form"},"source":["#@title Actualizar e instalar paquetes necesarios\n","!pip install -U --pre tensorflow==\"2.*\"\n","!pip install tf_slim\n","!pip install pycocotools"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sTbZzYL86uFo","cellView":"form"},"source":["#@title Clona el repositorio de modelos de TF si no está ya disponible\n","import os\n","import pathlib\n","\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RAQTRt6H7BOU","cellView":"form"},"source":["#@title Instalar el Object Detection API\n","# Nota: si falla por falta de requerimientos, ejecutarlo de nuevo y funcionará ;)...\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYK4yIhXzXwz","cellView":"form"},"source":["#@title Re-Instalar el Object Detection API (se ejecuta de nuevo para que lo instale bien)\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQC9P5-5tVvq","cellView":"form"},"source":["#@title Corrobora que se haya configurado un entorno con GPU \n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name == '/device:GPU:0':\n","  print('GPU encontrado: {}'.format(device_name))\n","else:\n","  print(\"NO SE ENCUENTRA GPU!!!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IKaBffWktMF_"},"source":["1) Define las librerías a utilizar:"]},{"cell_type":"code","metadata":{"id":"Boyh2gm1tRKA","cellView":"form"},"source":["#@title Cargar Librerías\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import os\n","import random\n","import io\n","import imageio\n","import glob\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from IPython.display import display, Javascript\n","from IPython.display import Image as IPyImage\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as vis_util\n","from object_detection.utils import colab_utils\n","from object_detection.builders import model_builder\n","from object_detection.utils import ops as utils_ops\n","\n","import tarfile\n","import time\n","import shutil\n","import re\n","\n","%matplotlib inline\n","\n","print(\"Librerías cargadas.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JnRw9NHCf04_","cellView":"form"},"source":["#@title Aplicar Patches\n","# patch tf1 into `utils.ops`\n","utils_ops.tf = tf.compat.v1\n","\n","# Patch the location of gfile\n","tf.gfile = tf.io.gfile\n","\n","print(\"Patches ejecutados\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_pYVA2k6tnTo"},"source":["2) Continua la preparación del ambiente para poder entrenar el modelo:"]},{"cell_type":"code","metadata":{"id":"p0hCz9mbthb-","cellView":"form"},"source":["#@title Ejecuta el constructor del modelo (\" model builder test \")\n","!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UuS1llDSuW17"},"source":["3) Monta el drive y configura las carpetas a usar:"]},{"cell_type":"code","metadata":{"id":"-EEKikq8zMBL","cellView":"form"},"source":["#@title Monta Google Drive\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# configuración de directorios local en Google Drive\n","drive_path = '/content/gdrive/My Drive/GEMIS/objDetectionCursogramas'\n","data_dir_path = drive_path + '/Cursogramas'\n","\n","print(\"\\n\")\n","print(\"> Datos disponibles en: \", data_dir_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"djpz2beJ7TdC"},"source":["4) Levantar la configuración de los TFRecords ya generados en base a los XMLs de las imágenes:"]},{"cell_type":"code","metadata":{"id":"GHQ-gs3iRWCv","cellView":"form"},"source":["#@title Definir los nombres de los archivos de configuración\n","train_record_fname = data_dir_path + '/train.record'\n","test_record_fname = data_dir_path + '/test.record'\n","label_map_pbtxt_fname = data_dir_path + '/label_map.pbtxt'\n","\n","print(\"> Archivos de configuracion:\")\n","\n","if os.path.isfile(train_record_fname):\n","  print(\"+\", train_record_fname, \" encontrado.\")\n","else:\n","  print(\"-\", train_record_fname, \" no encontrado!\")\n","\n","if os.path.isfile(test_record_fname):\n","  print(\"+\", test_record_fname, \" encontrado.\")\n","else:\n","  print(\"-\", test_record_fname, \" no encontrado!\")\n","\n","if os.path.isfile(label_map_pbtxt_fname):\n","  print(\"+\", label_map_pbtxt_fname, \" encontrado.\")\n","else:\n","  print(\"-\", label_map_pbtxt_fname, \" no encontrado!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HPn-r0U4zT94"},"source":["5) Configura el tipo de arquitectura & modelo a utilizar:\n","\n","Nota: se puede usar cualquiera de los disponibles en https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md falta agregar configuración."]},{"cell_type":"code","metadata":{"id":"q-a03Mbu3TIJ","cellView":"form"},"source":["# Parámetros para el entrenamiento\n","num_steps = 40000 #@param {type:\"number\"}\n","num_eval_steps = 750 #@param {type:\"number\"}\n","\n","# Modelo seleccionado para usar de base\n","# (seleccione alguno de `MODELS_CONFIG` \n","#          para obtener la configuración definida)\n","chosen_model = 'Faster R-CNN ResNet101' #@param ['efficientdet-d0', 'efficientdet-d1', 'efficientdet-d2', 'efficientdet-d3', 'efficientdet-d6', 'efficientdet-d7', 'CenterNet HourGlass104 (512)', 'CenterNet HourGlass104 (1024)', 'SSD ResNet101 V1 FPN', 'Faster R-CNN ResNet101', 'Faster R-CNN Inception ResNet v2' ]\n","\n","# indica el tamaño de las imagen del modelo \n","# (ojo que no todos lo permite cambiar)\n","tamanio_model = '640x640'  #@param ['640x640', '1024x1024' ]\n","\n","# define la configuración de los modelos\n","MODELS_CONFIG = {\n","      'efficientdet-d0': {\n","        'model_name': 'efficientdet_d0_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n","      \t'pretrained_checkpointURL': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/',\n","        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n","        'batch_size': 16,\n","        'cambio_tam_model' : False\n","    },\n","      'efficientdet-d1': {\n","        'model_name': 'efficientdet_d1_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n","\t'pretrained_checkpointURL': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/',\n","        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n","        'batch_size': 16,\n","        'cambio_tam_model' : False\n","    },\n","      'efficientdet-d2': {\n","        'model_name': 'efficientdet_d2_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n","      \t'pretrained_checkpointURL': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/',\n","        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n","        'batch_size': 16,\n","        'cambio_tam_model' : False\n","    },\n","      'efficientdet-d3': {\n","        'model_name': 'efficientdet_d3_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n","      \t'pretrained_checkpointURL': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/',\n","        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n","        'batch_size': 16,\n","        'cambio_tam_model' : False\n","    },\n","      'efficientdet-d6': {\n","        'model_name': 'efficientdet_d6_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d6_1408x1408_coco17_tpu-32.config',\n","      \t'pretrained_checkpointURL': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/',\n","        'pretrained_checkpoint': 'efficientdet_d6_coco17_tpu-32.tar.gz',\n","        'batch_size': 16,\n","        'cambio_tam_model' : False\n","    },\n","      'efficientdet-d7': {\n","        'model_name': 'efficientdet_d7_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d7_1536x1536_coco17_tpu-32.config',\n","      \t'pretrained_checkpointURL': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/',\n","        'pretrained_checkpoint': 'efficientdet_d7_coco17_tpu-32.tar.gz',\n","        'batch_size': 16,\n","        'cambio_tam_model' : False\n","    },\n","      'CenterNet HourGlass104 (512)': {                \n","        'model_name': 'centernet_hg104_512x512_coco17_tpu-8',\n","        'base_pipeline_file': 'centernet_hourglass104_512x512_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'centernet_hg104_512x512_coco17_tpu-8.tar.gz',\n","      \t'pretrained_checkpointURL': 'http://download.tensorflow.org/models/object_detection/tf2/20200713/',\n","        'batch_size': 4,\n","        'cambioTamanio' : False\n","    },\n","      'CenterNet HourGlass104 (1024)': {                \n","        'model_name': 'centernet_hg104_1024x1024_coco17_tpu-32.tar.gz',\n","        'base_pipeline_file': 'centernet_hourglass104_1024x1024_coco17_tpu-32.config',\n","        'pretrained_checkpoint': 'centernet_hg104_1024x1024_coco17_tpu-32.tar.gz',\n","      \t'pretrained_checkpointURL': 'http://download.tensorflow.org/models/object_detection/tf2/20200713/',\n","        'batch_size': 2,\n","        'cambioTamanio' : False\n","        },\n","      'SSD ResNet101 V1 FPN': {\n","        'model_name': 'ssd_resnet101_v1_fpn_640x640_coco17_tpu-8',\n","        'base_pipeline_file': 'ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz',\n","      \t'pretrained_checkpointURL': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/',\n","        'batch_size': 4,\n","        'cambioTamanio' : True\n","    },\n","      'Faster R-CNN ResNet101': {\n","        'model_name': 'faster_rcnn_resnet101_v1_640x640_coco17_tpu-8',\n","        'base_pipeline_file': 'faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz',\n","      \t'pretrained_checkpointURL': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/',\n","        'batch_size': 4,\n","        'cambioTamanio' : True        \n","    },  \n","      'Faster R-CNN Inception ResNet v2': {                \n","        'model_name': 'faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8',\n","        'base_pipeline_file': '',\n","        'pretrained_checkpoint': 'faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8.tar.gz',\n","\t      'pretrained_checkpointURL': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/',\n","        'batch_size': 4,\n","        'cambioTamanio' : True\n","    }    \n","}\n","\n","model_name = MODELS_CONFIG[chosen_model]['model_name']\n","pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n","pretrained_checkpointURL = MODELS_CONFIG[chosen_model]['pretrained_checkpointURL']\n","base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n","if MODELS_CONFIG[chosen_model]['cambioTamanio']:\n","  model_name = model_name.replace('640x640', tamanio_model)\n","  pretrained_checkpoint = pretrained_checkpoint.replace('640x640', tamanio_model)\n","  base_pipeline_file = base_pipeline_file.replace('640x640', tamanio_model)\n","##batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training\n","batch_size = 2 # se usa pequeño para que no falle de memoria\n","\n","print(\"> Configuración definida.\")\n","print(\"Modelo a usar: \", model_name)\n","print(\"Checkpoint a usar: \", pretrained_checkpoint)\n","print(\"Base Pipeline a usar: \", ('default' if base_pipeline_file == '' else base_pipeline_file))\n","print(\"Batch Size a usar: \", batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uNsUgl5zzgZQ","cellView":"form"},"source":["#@title Crear la carpeta temporal y descargar el modelo pre-entrenado\n","modelDeployDir = '/content/models/research/deploy/'\n","%mkdir {modelDeployDir}\n","%cd {modelDeployDir}\n","\n","# Baja el modelo pre-entrenado\n","download_tar = pretrained_checkpointURL + pretrained_checkpoint\n","!wget {download_tar}\n","tar = tarfile.open(pretrained_checkpoint)\n","tar.extractall()\n","tar.close()\n","\n","# Baja el archivo de configuracion base\n","if base_pipeline_file == '':\n","    # usa el config que vino en el checkpoint\n","    base_pipeline_file = model_name+'.config'\n","    shutil.copy(modelDeployDir+model_name+'/pipeline.config', modelDeployDir+base_pipeline_file)  \n","else:\n","    # baja y usa el config definido arriba\n","    %cd {modelDeployDir}\n","    download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n","    !wget {download_config}    \n","\n","# determina el nombre del archivo de configuración\n","pipeline_fname = modelDeployDir + base_pipeline_file\n","if os.path.isfile( pipeline_fname ):\n","  print(\"+\", pipeline_fname, \" encontrado.\")\n","else:\n","  print(\"-\", pipeline_fname, \" NO encontrado!!!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yhsmkeeV2VQH","cellView":"form"},"source":["#@title Cambiar el archivo de configuracion base para el entrenamiento\n","\n","# obtiene la cantidad de clases\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())\n","\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","##print(\"num_classes: \", num_classes)\n","\n","\n","# define nuevo archivo de configuración\n","pipeline_file = modelDeployDir + 'pipeline_file.config'\n","\n","# modifica el archivo de configuración\n","%cd {modelDeployDir}\n","print(\"\\nEscribiendo archivo de configuración: \", pipeline_file,\"\\n\")\n","\n","# modifica \n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open('pipeline_file.config', 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","                'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","\n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    \n","    #fine-tune checkpoint type\n","    s = re.sub(\n","        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n","        \n","    f.write(s)\n","\n","# muestra nuevo archivo modificado\n","%cat {pipeline_file}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3eIcLr6k3GaB"},"source":["6) Lleva a cabo el entrenamiento:"]},{"cell_type":"code","metadata":{"id":"hObf9Xse3bMS","cellView":"form"},"source":["#@title Ejecutar Entrenamiento\n","\n","# define carpeta donde se encuentra el modelo\n","model_dir = '/content/training/'\n","\n","# ejecuta el entrenamiento\n","start_time = time.time()\n","\n","print(\"\\n *************** comienza el entrenamiento \", time.strftime('%H:%M:%S'), \" ***************\")\n","print(\"\\n> Parámetros: \")\n","print(\"   - pipeline_config_path: \", pipeline_file)\n","print(\"   - model_dir: \", model_dir)\n","print(\"   - model_name: \", model_name)\n","print(\"   - num_train_steps: \", num_steps)\n","print(\"   - num_eval_steps: \", num_eval_steps)\n","print(\"   - batch_size: \", batch_size)\n","print(\"   - num_classes: \", num_classes)\n","print(\"\\n\\n\")\n","\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1 \\\n","    --num_eval_steps={num_eval_steps}\n","\n","end_time = time.time()\n","print(\"\\n *************** fin del entrenamiento \", time.strftime('%H:%M:%S'), \" ***************\")    \n","print(\"++ Duración del entrenamiento: \", (end_time-start_time)/60, \" minutos.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PL1b7JL3vLR","cellView":"form"},"source":["#@title Mostrar el tensorboard (opcional)\n","%load_ext tensorboard\n","%tensorboard --logdir '/content/training/train'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n_J5MBuWFb0Y"},"source":["6) Exportar el modelo entrenado para poder usarlo:"]},{"cell_type":"code","metadata":{"id":"qYe1SZYXxnZh","cellView":"form"},"source":["#@title Mostrar el contenido de carpeta donde se guardaron los checkpoints\n","print(\"> \",model_dir, \": \\n\")\n","print(\"\\n\")\n","%ls {model_dir}\n","print(\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DZtucLHN3_Od","cellView":"form"},"source":["#@title Exportar el checkpoint como modelo para usar\n","# convierte el modelo entrenado\n","output_directory = '/content/fine_tuned_model'\n","\n","#place the model weights you would like to export here\n","!python /content/models/research/object_detection/exporter_main_v2.py \\\n","    --trained_checkpoint_dir {model_dir} \\\n","    --output_directory {output_directory} \\\n","    --pipeline_config_path {pipeline_file}\n","\n","# copia los archivos del modelo entrenado al Drive para persistirlos\n","\n","# muestra el modelo exportado \n","output_directory = '/content/fine_tuned_model/saved_model/'\n","print(\"> \", output_directory ,\":\\n\")\n","!ls {output_directory}\n","print(\"\\n\")\n","\n","# crea directorio destino\n","dirDestDrive = drive_path + '/TF_model' \n","modelDrive = dirDestDrive + '/saved_model'\n","if not os.path.isdir(dirDestDrive):\n","  os.makedirs(dirDestDrive)\n","\n","# copia el modelo exportado\n","shutil.copytree(os.path.abspath(output_directory), modelDrive)\n","print(\"> Modelo \", output_directory, \"copiado a \", dirDestDrive)\n","##shutil.copytree(os.path.abspath('/content/fine_tuned_model/checkpoint'), modelDrive+'/fine_tuned_model_checkpoint')\n","\n","# copia la configuración del pipeline del modelo exportado\n","output_pipeline_fname = '/content/fine_tuned_model/pipeline.config'\n","shutil.copy(output_pipeline_fname, dirDestDrive)\n","print(\"> Configuración \", output_pipeline_fname, \" copiada a \", dirDestDrive)\n","\n","# copia la configuración del pipeline original de entrenamiento\n","shutil.copy(pipeline_fname, dirDestDrive)\n","print(\"> Configuración \", pipeline_fname, \" copiada a \", dirDestDrive)\n","\n","# copia la definicion de las etiquetas para mostrar\n","shutil.copy(data_dir_path + '/label_map.pbtxt', dirDestDrive)\n","print(\"> label_map.pbtxt copiada a \", dirDestDrive)\n","\n","# obtiene el último checkpoint\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'ckpt-' in l and '.index' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_checkpoint = lst[steps.argmax()].replace('.index', '')\n","\n","# copia los checkpoints del enetrenamiento del modelo\n","dirDestDriveCP = dirDestDrive + '/training_checkpoint'\n","if not os.path.isdir(dirDestDriveCP):\n","  os.makedirs(dirDestDriveCP)\n","shutil.copy(os.path.abspath(model_dir + '/checkpoint' ), dirDestDriveCP)\n","print(\"> Checkpoint copiado a \", dirDestDriveCP)\n","for fCP in os.listdir(model_dir):\n","    if fCP.startswith( last_checkpoint ):\n","      shutil.copy(os.path.abspath(model_dir + '/' + fCP), dirDestDriveCP)\n","      print(\"> Checkpoint \", fCP,\" copiado a \", dirDestDriveCP)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZsCjOoq0LvDf"},"source":["7) Probar el modelo entrenado y exportado con las imágenes de validación:"]},{"cell_type":"code","metadata":{"id":"d3HT7Mu3lfut","cellView":"form"},"source":["#@title Seleccionar y cargar las imágenes para usar en la prueba\n","valImagesPath = data_dir_path + '/validation/images'\n","\n","valImages = os.listdir(valImagesPath)[:10] # sólo 10 para probar\n","print(\"> Cantidad de imágenes cargadas: \", len(valImages))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iMQIWnuVnu0W","cellView":"form"},"source":["#@title Cargar configuración para la prueba\n","# recupera la configuración del drive\n","configs = config_util.get_configs_from_pipeline_file(dirDestDrive + '/pipeline.config')\n","\n","# carga la definición de las clases\n","label_map_path = configs['eval_input_config'].label_map_path\n","label_map = label_map_util.load_labelmap(label_map_path)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map,\n","    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n","    use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)\n","\n","print(\"> categories: \", len(categories))\n","print(\"> category_index: \", len(category_index))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EhqNBc7QmYew","cellView":"form"},"source":["#@title Define funciones auxiliares para procesar las imágenes\n","\n","def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: a file path.\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)\n","\n","def plot_detections(image_np,\n","                    boxes,\n","                    classes,\n","                    scores,\n","                    category_index):\n","  \"\"\"Wrapper function to visualize detections.\n","\n","  Args:\n","    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n","    boxes: a numpy array of shape [N, 4]\n","    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n","      and match the keys in the label map.\n","    scores: a numpy array of shape [N] or None.  If scores=None, then\n","      this function assumes that the boxes to be plotted are groundtruth\n","      boxes and plot all boxes as black with no classes or scores.\n","    category_index: a dict containing category dictionaries (each holding\n","      category index `id` and category name `name`) keyed by category indices.\n","    figsize: size for the figure.\n","    image_name: a name for the image file.\n","  \"\"\"\n","  image_np_with_annotations = image_np.copy()\n","\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_annotations,\n","      boxes,\n","      classes,\n","      scores,\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=100,\n","      min_score_thresh=0.6,\n","      agnostic_mode=False)\n","\n","  display(Image.fromarray(image_np_with_annotations))  \n","\n","  print(\" objetos detectados: \", len(classes))\n","\n","\n","def run_inference_for_single_image(model, image):\n","  image = np.asarray(image)\n","  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","  input_tensor = tf.convert_to_tensor(image)\n","  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","  input_tensor = input_tensor[tf.newaxis,...]\n","\n","  # Run inference\n","  model_fn = model.signatures['serving_default']\n","  output_dict = model_fn(input_tensor)\n","\n","  # All outputs are batches tensors.\n","  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","  # We're only interested in the first num_detections.\n","  num_detections = int(output_dict.pop('num_detections'))\n","  output_dict = {key:value[0, :num_detections].numpy() \n","                 for key,value in output_dict.items()}\n","  output_dict['num_detections'] = num_detections\n","\n","  # detection_classes should be ints.\n","  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n","   \n","  # Handle models with masks:\n","  if 'detection_masks' in output_dict:\n","    # Reframe the the bbox mask to the image size.\n","    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","              output_dict['detection_masks'], output_dict['detection_boxes'],\n","               image.shape[0], image.shape[1])      \n","    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n","                                       tf.uint8)\n","    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","    \n","  return output_dict\n","\n","def show_inference(model, image_path):\n","  # the array based representation of the image will be used later in order to prepare the\n","  # result image with boxes and labels on it.\n","  image_np = np.array(Image.open(image_path))\n","  # Actual detection.\n","  output_dict = run_inference_for_single_image(model, image_np)\n","  # Visualization of the results of a detection.\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks_reframed', None),\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=300,\n","      line_thickness=8,\n","      agnostic_mode=False)\n","\n","  display(Image.fromarray(image_np))  \n","  print(\" objetos detectados: \", len(output_dict['detection_classes']))\n","  \n","\n","print(\"Funciones auxiliares definidas.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYtK8veclf_E"},"source":["7a) Realiza la prueba utilizando el Modelo Exportado que se encuentra copiado en el drive:"]},{"cell_type":"code","metadata":{"id":"w-kR-3vQksmV","cellView":"form"},"source":["#@title Cargar el modelo exportado \n","detection_model = tf.saved_model.load(str(modelDrive))\n","print(\"> detection_model: \", detection_model, \" cargado.\")\n","\n","# muestra info de configuración\n","print(detection_model.signatures['serving_default'].inputs)\n","detection_model.signatures['serving_default'].output_dtypes\n","detection_model.signatures['serving_default'].output_shapes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T2pBmtLnmJCx","cellView":"form"},"source":["#@title Prrocesa imágenes de valicación y mostrar los resultados\n","for im in valImages:\n","  print(\"\\n> \", im, \": \")\n","  show_inference(detection_model, valImagesPath + '/' + im)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x896Lz66lQyl"},"source":["7a) Realiza la prueba utilizando el Último Checkpoint del Entrenamiento que se ha copiado al drive:\n","\n","*Nota: en caso que se desee se puede cambiar 'checkpointCargar' para utilizar cualquiera de los checkpoints disponibles *"]},{"cell_type":"code","metadata":{"id":"KQi6hW6gq2p0","cellView":"form"},"source":["#@title Cargar el último checkpoint del entrenamiento\n","\n","# Determinar checkpoint a usar\n","checkpointCargar = dirDestDriveCP + '/' + last_checkpoint\n","\n","# recupera la configuración del tipo de modelo \n","model_config = configs['model']\n","detection_model = model_builder.build(\n","      model_config=model_config, is_training=False)\n","\n","# recupera el checkpoint del modelo\n","ckpt = tf.compat.v2.train.Checkpoint(\n","      model=detection_model)\n","ckpt.restore(checkpointCargar)\n","\n","def get_model_detection_function(model):\n","  \"\"\"Get a tf.function for detection.\"\"\"\n","\n","  @tf.function\n","  def detect_fn(image):\n","    \"\"\"Detect objects in image.\"\"\"\n","\n","    image, shapes = model.preprocess(image)\n","    prediction_dict = model.predict(image, shapes)\n","    detections = model.postprocess(prediction_dict, shapes)\n","\n","    return detections, prediction_dict, tf.reshape(shapes, [-1])\n","\n","  return detect_fn\n","\n","detect_fn = get_model_detection_function(detection_model)\n","\n","print(\"Checkpoint \", last_checkpoint, \" cargado.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VT-huiMFrNX5","cellView":"form"},"source":["#@title Probar con el último checkpoint cargado\n","\n","# procesa las imágenes cargadas\n","for im in valImages:\n","\n","    print(\"\\n> \",  im, \": \")\n","\n","    image_path = valImagesPath + '/' + im\n","\n","    # open file to process\n","    image = Image.open(image_path)\n","\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image_path)\n","\n","    input_tensor = tf.convert_to_tensor(\n","        np.expand_dims(image_np, 0), dtype=tf.float32)\n","    detections, predictions_dict, shapes = detect_fn(input_tensor)\n","\n","    label_id_offset = 1\n","    image_np_with_detections = image_np.copy()\n","\n","    # Visualization of the results of a detection.\n","    plot_detections(image_np_with_detections,\n","          detections['detection_boxes'][0].numpy(),\n","          (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n","          detections['detection_scores'][0].numpy(),\n","          category_index)\n","\n"],"execution_count":null,"outputs":[]}]}