{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"c3-Test-Check-Detectar-Objetos.ipynb","provenance":[{"file_id":"1ZqC7qID9bdT9BL0hRfk9amySJidFq-7k","timestamp":1577829312762}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"pHefTSRioYTI"},"source":["# Lleva a cabo una Prueba Inicial del Modelo Entrenado con TF 2 viendo los objetos detectados en las imágenes de validación, también hace una prueba del OCR de los objetos (opcional)"]},{"cell_type":"markdown","metadata":{"id":"XKXKZbK5RPQZ"},"source":["0) Preparar ambiente e instalar paquetes:"]},{"cell_type":"code","metadata":{"id":"GCD3yzfvRY8e","cellView":"form"},"source":["#@title Clonar el repositorio de modelos de TF si no está ya disponible\n","import os\n","import pathlib\n","\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6irvujkJwL52","cellView":"form"},"source":["#@title Instalar el Object Detection API\n","# Nota: si dice que faltan librerías, ignorar (funciona bien igual) \n","#       sino volverlo a ejecutar esta celda para que reinistale y entonces dice todo \"successfully\"\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5hA-4aTnLL19","cellView":"form"},"source":["#@title Baja e instala los paquetes de Tesseract-OCR (opcional, sólo si se quiere probar OCR)\n","!pip install pytesseract\n","!sudo apt install tesseract-ocr"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PEeuRn1wRjNz"},"source":["\n","1) Cargar librerías:"]},{"cell_type":"code","metadata":{"id":"MrgXb3574eAx","cellView":"form"},"source":["#@title Cargar Librerías\n","import os\n","import os.path\n","import sys\n","import numpy as np\n","\n","import tensorflow as tf\n","\n","from IPython.display import Image, display\n","from PIL import Image as ImPIL\n","\n","import csv\n","\n","print (\"Librerías cargadas.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Ly3kAM3qsLo"},"source":["2) Montar el Drive:"]},{"cell_type":"code","metadata":{"id":"LdUm8v20sawT","cellView":"form"},"source":["#@title Montar Google Drive\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieCbCWpM9-W9","cellView":"form"},"source":["#@title Definir configuración de directorios local en Google Drive\n","drive_path = '/content/gdrive/My Drive/GEMIS/objDetectionCursogramas'\n","data_dir_path = drive_path + '/Cursogramas'\n","model_drive_path = drive_path + '/TF_model'\n","\n","print(\"Configuración de archivos definida.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6TSvP04bfOJG"},"source":["3) Cargar el modelo entrenado:"]},{"cell_type":"code","metadata":{"id":"Ue0RFAprfOeF","cellView":"form"},"source":["#@title Cargar el modelo de object detection entrenado y define funciones auxiliares\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","\n","# carga el modelo exportado \n","ModelObjDetEntrenado = model_drive_path + '/saved_model'\n","detection_model = tf.saved_model.load(str(ModelObjDetEntrenado))\n","print(\"\\nModelo objDetector cargado: [\", ModelObjDetEntrenado, \"]: \", detection_model)\n","\n","# archivo con lista de clases para reconocer \n","labelMapFile = model_drive_path + '/label_map.pbtxt'\n","\n","label_map = label_map_util.load_labelmap(labelMapFile)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map,\n","    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n","    use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)\n","print(\"\\nDefinición de Clases cargada: [\", labelMapFile, \"]: \", len(category_index))\n","\n","# Size, in inches, of the output images.\n","##IMAGE_SIZE = (12, 8)\n","##print(\"\\nIMAGE SIZE: \",  IMAGE_SIZE)\n","\n","## funciones auxiliares\n","\n","# función auxiliar para conversión de la imagen ( NO SE USA )\n","#def load_image_into_numpy_array(image):\n","#    (im_width, im_height) = image.size\n","#    return np.array(image.getdata()).reshape(\n","#        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# función auxiliar para procesar la imagen con el modelo\n","def run_inference_for_single_image(model, image_np):   \n","    # fuerza conversión a array por las dudas\n","    image_np = np.asarray(image_np) \n","    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","    input_tensor = tf.convert_to_tensor(image_np)\n","    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","    input_tensor = input_tensor[tf.newaxis,...]\n","\n","    # Run inference\n","    model_fn = model.signatures['serving_default']\n","    output_dict = model_fn(input_tensor)\n","\n","    # All outputs are batches tensors.\n","    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","    # We're only interested in the first num_detections.\n","    num_detections = int(output_dict.pop('num_detections'))\n","    output_dict = {key:value[0, :num_detections].numpy() \n","                  for key,value in output_dict.items()}\n","    output_dict['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n","    \n","    # Handle models with masks:\n","    if 'detection_masks' in output_dict:\n","      # Reframe the the bbox mask to the image size.\n","      detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                output_dict['detection_masks'], output_dict['detection_boxes'],\n","                image.shape[0], image.shape[1])      \n","      detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n","                                        tf.uint8)\n","      output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","      \n","    return output_dict\n","\n","# función auxiliar para mostrar resultados de procesar la imagen con el modelo\n","def plot_detections(image_np,\n","                    boxes,\n","                    classes,\n","                    scores,\n","                    category_index,\n","                    line_thickness = 8,\n","                    min_score = 0.8):\n","\n","  # genera una copia de la imagen\n","  image_np_with_annotations = image_np.copy()\n","\n","  # en la copia marca los objetos detectados\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_annotations,\n","      boxes,\n","      classes,\n","      scores,\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=100,\n","      line_thickness=line_thickness,\n","      min_score_thresh=min_score,\n","      agnostic_mode=False)\n","\n","  # muestra la copia de la imagen con los objetos detectados\n","  display(ImPIL.fromarray(image_np_with_annotations))  \n","  #print(\"-- objetos detectados: \", len(classes), \"\\n\")  # siempre son 300\n","\n","print(\"\\nFunciones Auxiliares definidas.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNL3PFXmLkUM","cellView":"form"},"source":["#@title Carga la configuración de los símbolos del Cursograma (opcional, sólo se quiere para usar OCR)\n","\n","# carga la información de un archivo CSV\n","##model_drive_path\n","config_simbolos_file = model_drive_path + '/simbolos_config.csv'\n","##config_simbolos_file = drive_path + model_drive_path + '/simbolos_config.csv'\n","with open(config_simbolos_file, mode='r') as csvfile:\n","    lineasCSV = list(csv.reader(csvfile))\n","\n","# procesa el archivo CSV \n","# pero sólo levante lo de OCR\n","auxList = []\n","for l in lineasCSV:\n","  # si no se debe ignorar el simbolo\n","  if l[0][0] != \"#\":     \n","      # carga la configuración del símbolo (aunque se ignore en la comparación)\n","      # campo clave: nombre - valores: [descripción, claseAgrupa, ignora?, cambiarAreaY?, cambiarAreaX?, OCRconfig, OCRcropDesp] \n","      OCRconfig = int(l[6])\n","      if OCRconfig <= 0:\n","        # si no tiene definido que haga el OCR, fuerza a que lo haga\n","        OCRconfig = 9\n","      auxList.append( ( l[0], [ OCRconfig, l[7] ] ) )\n","\n","# genera dicccionario de la configuración de símbolos\n","config_simbolos = dict(auxList)\n","\n","print(\">Configuración de símbolos: \")\n","print(\"  cargada de [\", config_simbolos_file, \"] \")\n","print(\"  valores: nombre + [OCRconfig, OCRcropDesp] ] \")\n","print(\"  \", config_simbolos)\n","\n","# constantes de posicion de configuraciones\n","config_posOCRconfig = 0\n","config_posOCRcropDesp = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-vLHZTM1QJcX","cellView":"form"},"source":["#@title Definir función auxiliar para hacer el OCR (opcional) { run: \"auto\" }\n","import pytesseract\n","\n","# parámetros auxiliares para debug\n","muestraDetalleDebug = True #@param {type:\"boolean\"}\n","muestraDetalleObjDetectadosEnImagen = True #@param {type:\"boolean\"}\n","\n","# función auxiliar para realizar el OCR de los símbolos que corresponda\n","# devuelve el texto obtenido del OCR\n","# nota: está es la misma función que usa el Evaluador\n","def hacerOCR(imageCargada, class_name, nuevoRangoIm):\n","    resOCR = ''\n","    if class_name in config_simbolos and config_simbolos[class_name][config_posOCRconfig]>0:\n","    # si es una clase que se procesa el OCR\n","        # si es una clase que se procesa el OCR\n","        if config_simbolos[class_name][config_posOCRcropDesp]!=\"\" and config_simbolos[class_name][config_posOCRcropDesp]!=\"-\" and config_simbolos[class_name][config_posOCRcropDesp]!=\"*\":\n","          # si corresponde achicar la imagen\n","          cropOCRdespPorc = config_simbolos[class_name][config_posOCRcropDesp].split(\"*\")\n","          if len(cropOCRdespPorc)==4:\n","              # toma de la configuración los valores para reducir el tamaño de la subimagen\n","              imAncho = (nuevoRangoIm[2] - nuevoRangoIm[0])\n","              imAlto = (nuevoRangoIm[3] - nuevoRangoIm[1])\n","              nuevoRangoIm = (  nuevoRangoIm[0] + (imAncho * int(cropOCRdespPorc[0]) ) // 100,\n","                                nuevoRangoIm[1] + (imAlto * int(cropOCRdespPorc[1]) ) // 100,\n","                                nuevoRangoIm[2] - (imAncho * int(cropOCRdespPorc[2]) ) // 100,\n","                                nuevoRangoIm[3] - (imAlto *  int(cropOCRdespPorc[3]) ) // 100\n","                                    )\n","\n","        # toma la parte de la imagen que corresponde al objeto             \n","        imDetObj = imageCargada.crop( nuevoRangoIm )\n","        if muestraDetalleDebug and muestraDetalleObjDetectadosEnImagen:\n","            display( imDetObj )\n","\n","        # procesa el OCR y formatea\n","        resOCR = pytesseract.image_to_string(imDetObj, lang='eng', config='--psm '+str(config_simbolos[class_name][config_posOCRconfig]))\n","        resOCR = resOCR.replace(\"\\n\", \"\").upper().strip()\n","        if muestraDetalleDebug:\n","            print(\"   hacerOCR -- Parámetros: class_name (\", class_name, \")  - nuevoRangoIm (\", nuevoRangoIm, \") --> resOCR: \", resOCR)\n","\n","    return resOCR\n","\n","print(\"Funcón auxiliar hacerOCR definida.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uX-34hnJ3ub0"},"source":["4) Llevar a cabo la detección de objetos sobre las imágenes de validación:"]},{"cell_type":"code","metadata":{"id":"qxwIEKoU-qVB","cellView":"form"},"source":["#@title Definir imágenes a utilizar\n","\n","# define la carpeta donde están las imágenes para procesar\n","dirTest = data_dir_path + '/validation/images' \n","##dirTest = data_dir_path + '/Generados' \n","#dirTest = data_dir_path + '/Para-Evaluar' \n","\n","# levanta las imágenes de prueba para procesar\n","process_FileNames = [ fn for fn in os.listdir( dirTest ) if fn.endswith('.png') or fn.endswith('.jpg') ]\n","print(\"> Imágenes a probar: \", len(process_FileNames))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvoNuTau2IKw","cellView":"form"},"source":["#@title Tomar una muestra de las imágenes (si es necesario o se quiere) { run: \"auto\" }\n","\n","porcMuestraImagenesProcesar = 5  #@param {type:\"slider\", min:0, max:100, step:5}\n","if porcMuestraImagenesProcesar>0 and porcMuestraImagenesProcesar<100:\n","  cantProcesar = int(len(process_FileNames)*porcMuestraImagenesProcesar/100)\n","  if cantProcesar==0:\n","    cantProcesar = 1\n","  process_FileNames = process_FileNames[:cantProcesar]\n","print(\"> Imágenes/XML a probar: \", len(process_FileNames))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nwwnSO_83y5D","cellView":"form"},"source":["#@title Mostrar los objetos detectados en las imágenes\n","\n","# define minima probabilidad a usar\n","minimaProbabilidadObjectDetection = 90 #@param {type:\"slider\", min:1, max:100, step:1.0}\n","minProbObjDet = minimaProbabilidadObjectDetection / 100.0\n","\n","# define si muestra detalle o no\n","muestraDetalleSubImagenes = False #@param {type:\"boolean\"}\n","\n","# define si ejecuta OCR en sub-imagenes\n","EjecutaOCRenSubImagenes = False #@param {type:\"boolean\"}\n","\n","muestraOCRSubImagenes = EjecutaOCRenSubImagenes\n","\n","# procesa las imágenes \n","for fn in process_FileNames:\n","\n","  # define archivo a procesar y generar\n","  imagenProcesar = dirTest + '/' + fn\n","\n","  print(\"\\n\\n> \", imagenProcesar, \": \")\n","  \n","  # open file to process\n","  imageCargada = ImPIL.open(imagenProcesar) \n","\n","  # Convierte la imagen a escala de grises y luego a RGB \n","  # (para sacarle los colores que tuviera previamente y dejarlo con 3 canales de profundidad)\n","  imageCargada = imageCargada.convert('L')\n","  imageCargada = imageCargada.convert('RGB')\n","\n","  # obtiene el tamaño de la imagen\n","  imCargada_ancho, imCargada_alto = imageCargada.size\n","\n","  # convierte la imagen a un array \n","  image_np = np.array(imageCargada)\n","  \n","  # Obtiene el tamaño de la imagen\n","  print(\"\\n  tamaño de la imagen: \", image_np.shape, \"\\n\")\n","\n","  # Procesa el array de la imagen con el modelo cargado\n","  output_dict = run_inference_for_single_image(detection_model, image_np)\n","\n","  # muestra los resultados\n","  plot_detections(\n","      image_np = image_np,\n","      boxes = output_dict['detection_boxes'],\n","      classes = output_dict['detection_classes'],\n","      scores = output_dict['detection_scores'],\n","      category_index = category_index,\n","      min_score = minProbObjDet)\n","\n","  # muestra la imagen con los objetos detectados\n","  ##display( ImPIL.fromarray(image_np, 'RGB') )\n","\n","  if muestraDetalleSubImagenes or muestraOCRSubImagenes:   \n","\n","      # procesa los objetos detectados\n","      for detClass, detBox, detScore in zip(  output_dict['detection_classes'], output_dict['detection_boxes'], output_dict['detection_scores'] ):\n","\n","        class_name = category_index[detClass]['name']\n","\n","        # como las coordenadas están normalizadas las debe convertir \n","        # teniendo en cuenta el tamaño de la imagen\n","        # además notar que vienen datas en otro orden\n","        # - detBox = (ini alto, ini ancho, fin alto, fin ancho)\n","        # - nuevoRangoIn = (ini ancho x1, ini alto y1, fin ancho x2, fin alto y2)    \n","        nuevoRangoIm = [detBox[1] * imCargada_ancho, \n","                        detBox[0] * imCargada_alto,\n","                        detBox[3] * imCargada_ancho,\n","                        detBox[2] * imCargada_alto]\n","\n","        # si el objeto detectado tiene un puntaje superior o igual al mínimo\n","        if detScore >= minProbObjDet:\n","\n","            # calcula un valor para poder ordenar las figuras de arriba a abajo y izquierda a derecha\n","            centroideIm = nuevoRangoIm[1]*100000+nuevoRangoIm[0]\n","\n","            # extrae la subimagen de acuerdo al área indicada por el detector        \n","            imDetObj = imageCargada.crop( nuevoRangoIm )\n","            imAncho, imAlto = imDetObj.size\n","\n","            # muestra la sub-imagen\n","            print(\"\\n\")\n","            if muestraDetalleSubImagenes:              \n","              display( imDetObj )\n","\n","            # muestra resultados\n","            print(\"    - detecta \", class_name, \" : \", detScore*100, \"% : \", detBox, \"con centroide: \", centroideIm)\n","\n","            # devuelve resultados del OCR\n","            if EjecutaOCRenSubImagenes:\n","              resOCR = hacerOCR(imageCargada, class_name, nuevoRangoIm)\n","              print(\"    * resOCR: \", resOCR)\n","        \n","        else:\n","              if detScore >= 0.4:\n","                print(\"-- objeto descartado por bajo score: \", class_name, \"(\", detScore*100, \"%) en \", nuevoRangoIm)\n","\n"],"execution_count":null,"outputs":[]}]}