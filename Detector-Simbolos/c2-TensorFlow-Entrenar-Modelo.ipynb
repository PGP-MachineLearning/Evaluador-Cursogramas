{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"c2-TensorFlow-Entrenar-Modelo.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pHefTSRioYTI","colab_type":"text"},"source":["# Realiza el Entrenamiento del Modelo para Detección de los Operadores de un Cursograma usando  los modelos provistos por TensorFlow\n","Fuente: https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/\n"]},{"cell_type":"markdown","metadata":{"id":"jKsjtRyL56Zm","colab_type":"text"},"source":["0) Preparar el ambiente:"]},{"cell_type":"code","metadata":{"id":"_x7FQvZKVxgC","colab_type":"code","colab":{}},"source":["#Configura el entorno usando versión 1 de TF\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-EEKikq8zMBL","colab_type":"code","colab":{}},"source":["# monta Google Drive:\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# configuración de directorios local en Google Drive\n","drive_path = '/content/gdrive/My Drive/GEMIS/objDetectionCursogramas'\n","data_dir_path = drive_path + '/Cursogramas'\n","repo_dir_path = drive_path + '/TF_object_detection_demo-master'\n","\n","print(\"\\n\")\n","print(\"> Datos disponibles en: \", data_dir_path)\n","print(\"> Código auxiliar disponible en: \", repo_dir_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p76juZ91zNCU","colab_type":"code","colab":{}},"source":["# instala requerimientos de object_detection_demo-master (por las dudas)\n","%cd {repo_dir_path}\n","!pip3 install -r requirements.txt\n","\n","print(\"Antes de continuar toque [RESTART RUNTIME] por favor...\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XKXKZbK5RPQZ","colab_type":"text"},"source":["1) Continua preparando el ambiente e instalar paquetes:\n","Nota: algunas cosas se repiten porque como resultado del anterior se reinicia el entorno."]},{"cell_type":"code","metadata":{"id":"cov2LNFYziUG","colab_type":"code","colab":{}},"source":["#Configura nuevamente el entorno usando versión 1 de TF\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EIh6n8WGyoZw","colab_type":"code","colab":{}},"source":["# Corrobora que se haya configurado un entorno con GPU\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU no encontrado')\n","else:\n","  print('GPU encontrado: {}'.format(device_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-a03Mbu3TIJ","colab_type":"code","colab":{}},"source":["# Parámetros para el entrenamiento\n","num_steps = 5000 #@param {type:\"number\"}\n","num_eval_steps = 50 #@param {type:\"number\"}\n","\n","# Modelo seleccionado para usar de base\n","# (seleccione alguno de `MODELS_CONFIG` \n","#   para obtener la configuración definida)\n","selected_model = 'rfcn_resnet101' #@param [\"ssd_mobilenet_v2\", \"faster_rcnn_inception_v2\", \"rfcn_resnet101\"]\n","\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 8\n","    }\n","}\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']\n","\n","print(\"> Configuración definda.\")\n","print(\"Modelo a usar: \", MODEL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zaf8yMH04Uqy","colab_type":"code","colab":{}},"source":["# Baja e instala los parquetes de 'Object Detection' de Tensor Flow a utilizar \n","# en el disco temporal de Colab (demora un ratito)\n","!pip install tf_slim\n","\n","%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","model_dir = 'training/'\n","\n","!python object_detection/builders/model_builder_test.py\n","\n","os.environ['PYTHONPATH'] += ':/content/models/research/object_detection:/content/models/research/slim/object_detection'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"65RSIsHS9_bo","colab_type":"code","colab":{}},"source":["# baja el modelo seleccionado \n","# en el disco temporal de Colab\n","# para utilizar como base\n","%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)\n","\n","# corrobora que se hayan bajado los archivos del modelo\n","print(\"\\n\")\n","!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}\n","print(\"\\n\")\n","\n","# configura el checkpoint a usar en el entrenamiento\n","fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eiEs_Q3K6WN5","colab_type":"code","colab":{}},"source":["# monta Google Drive nuevamente (se pierde conexión cuando se reinicia el entrorno anterior)\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# configuración de directorios local en Google Drive\n","drive_path = '/content/gdrive/My Drive/GEMIS/objDetectionCursogramas'\n","data_dir_path = drive_path + '/Cursogramas'\n","repo_dir_path = drive_path + '/TF_object_detection_demo-master'\n","\n","print(\"\\n\")\n","print(\"> Datos disponibles en: \", data_dir_path)\n","print(\"> Código auxiliar disponible en: \", repo_dir_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"djpz2beJ7TdC","colab_type":"text"},"source":["2) Generar TFRecords en base a los XMLs correspondientes a las imágenes:"]},{"cell_type":"code","metadata":{"id":"GHQ-gs3iRWCv","colab_type":"code","colab":{}},"source":["%cd {data_dir_path}\n","\n","# define los nombres de los archivos\n","train_csv_fname = data_dir_path + '/train_labels.csv'\n","test_csv_fname = data_dir_path + '/test_labels.csv'\n","train_record_fname = data_dir_path + '/train.record'\n","test_record_fname = data_dir_path + '/test.record'\n","label_map_pbtxt_fname = data_dir_path + '/label_map.pbtxt'\n","\n","# variables auxiliares para evitar problemas por espacio en 'My Drive'\n","aux_repo_dir_path=repo_dir_path.replace(\" \", \"\\ \")\n","aux_data_dir_path=data_dir_path.replace(\" \", \"\\ \")\n","aux_train_csv_fname = train_csv_fname.replace(\" \", \"\\ \")\n","aux_test_csv_fname = test_csv_fname.replace(\" \", \"\\ \")\n","aux_train_record_fname = train_record_fname.replace(\" \", \"\\ \")\n","aux_test_record_fname= test_record_fname.replace(\" \", \"\\ \")\n","aux_label_map_pbtxt_fname = label_map_pbtxt_fname.replace(\" \", \"\\ \")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kplWBZNd8us0","colab_type":"code","colab":{}},"source":["# por las dudas elimina los archivos si ya existen (para asegurar su actualización)\n","if os.path.isfile(train_csv_fname):\n","  os.remove(train_csv_fname)\n","if os.path.isfile(test_csv_fname):\n","  os.remove(test_csv_fname)\n","if os.path.isfile(train_record_fname):\n","  os.remove(train_record_fname)\n","if os.path.isfile(test_record_fname):\n","  os.remove(test_record_fname)\n","if os.path.isfile(label_map_pbtxt_fname):\n","  os.remove(label_map_pbtxt_fname)\n","\n","# convierte los XMLs de entrenamiento en un único archivo XML\n","# también genera el archivo `label_map.pbtxt` en el directorio `data/` \n","print(\"\\n-- xml_to_csv.py train\")\n","!python {aux_repo_dir_path}/xml_to_csv.py -i {aux_data_dir_path}/train/annotations -o {aux_train_csv_fname} -l {aux_data_dir_path}/\n","\n","# convierte los XMLs de validación en un único archivo XML\n","print(\"\\n-- xml_to_csv.py validation\")\n","!python {aux_repo_dir_path}/xml_to_csv.py -i {aux_data_dir_path}/validation/annotations -o {aux_test_csv_fname}\n","\n","# genera `train.record` para entrenamiento\n","print(\"\\n-- generate_tfrecord.py train_labels.csv\")\n","!python {aux_repo_dir_path}/generate_tfrecord.py --csv_input={aux_train_csv_fname} --output_path={aux_train_record_fname} --img_path={aux_data_dir_path}/train/images --label_map {aux_label_map_pbtxt_fname}\n","  \n","# genera `test.record` para validación\n","print(\"\\n-- generate_tfrecord.py test_labels.csv\")\n","!python {aux_repo_dir_path}/generate_tfrecord.py --csv_input={aux_test_csv_fname} --output_path={aux_test_record_fname} --img_path={aux_data_dir_path}/validation/images --label_map {aux_label_map_pbtxt_fname}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7f_8gnts_aXW","colab_type":"text"},"source":["3) Configura el 'Pipeline' con la configuración para el entrenamiento del modelo seleccionado:"]},{"cell_type":"code","metadata":{"id":"bkwi9JYN_Pzq","colab_type":"code","colab":{}},"source":["%cd /content/models/research\n","\n","import os\n","import re\n","\n","# define la configuración \n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n","\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())\n","\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","\n","# graba la configuración en el archivo correspondiente\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)\n","\n","print(\"Pipeline generado: \", pipeline_fname)\n","\n","# muestra el contenido del pipeline\n","!cat {pipeline_fname}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3JRuBXJhDhu5","colab_type":"text"},"source":["4) Preparar elementos para el entrenamiento:"]},{"cell_type":"code","metadata":{"id":"-V3FlEmUDjs-","colab_type":"code","colab":{}},"source":["# A) Limpia el contenido del directorio de salida para que trabaje de cero \n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)\n","\n","print(\"\\n\")\n","!echo {model_dir}\n","!ls -alh {model_dir}\n","print(\"\\n\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q2Z44wlfFMfH","colab_type":"text"},"source":["5) Realizar el entrenamiento:"]},{"cell_type":"code","metadata":{"id":"lLvOcO2aFQgo","colab_type":"code","colab":{}},"source":["import time\n","start_time = time.time()\n","\n","print(\"\\n *** comienza entrenamiento  \", start_time,\" ***\")\n","!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}\n","\n","end_time = time.time()\n","print(\"\\n *** fin del entrenamiento \", end_time, \" ***\")    \n","print(\"Duración del entrenamiento: \", (end_time-start_time)/60, \" minutos\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n_J5MBuWFb0Y","colab_type":"text"},"source":["6) Exportar el modelo entrenado para poder usarlo:"]},{"cell_type":"code","metadata":{"id":"OSJF3ki3Fnj6","colab_type":"code","colab":{}},"source":["# muestra los checkpoints generados disponibles para el modelo entrenado\n","# notar que sólo genera checkpoints si el loss baja \n","!ls {model_dir}\n","\n","# congela y exporta el último checkpoint para el modelo entrenado\n","import re\n","import numpy as np\n","\n","output_directory = './fine_tuned_model'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(\"\\n> Checkpoint para exportar: \", last_model_path)\n","\n","print(\"\\n *** comienza exportación del modelo ***\")\n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}\n","print(\"\\n *** fin de exportación del modelo ***\")\n","\n","# muestra el modelo exportado \n","print(\"\\n\\n\")\n","!ls {output_directory}\n","print(\"\\n\")\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)\n","!ls -alh {pb_fname}\n","\n","# copia el modelo entrenado y exportado al Drive \n","import shutil\n","import os\n","\n","dirDestDrive = drive_path + '/TF_model' \n","if not os.path.isdir(dirDestDrive):\n","  os.makedirs(dirDestDrive)\n","\n","# copia el modelo\n","shutil.copy(pb_fname, dirDestDrive)\n","print(\"> Modelo \", pb_fname, \"copiado a \", dirDestDrive)\n","\n","# copia la configuración del pipeline\n","shutil.copy(pipeline_fname, dirDestDrive)\n","print(\"> Configuración \", pipeline_fname, \" copiada a \", dirDestDrive)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZsCjOoq0LvDf","colab_type":"text"},"source":["7) Probar el modelo entrenado y exportado con las imágenes de validación:"]},{"cell_type":"code","metadata":{"id":"BF6ceJGAL1i5","colab_type":"code","colab":{}},"source":["import os\n","import glob\n","\n","# path donde está el modelo exportado\n","PATH_TO_CKPT = drive_path + '/TF_model/frozen_inference_graph.pb'\n","\n","# archivo con lista de etiquetas para mostrar \n","PATH_TO_LABELS = data_dir_path + '/label_map.pbtxt'\n","\n","# path donde están las imágenes a procesar\n","PATH_TO_TEST_IMAGES_DIR = data_dir_path + '/validation/images'\n","\n","# carga las imágenes a procesar \n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))[:15] # sólo 10 para probar\n","assert len(TEST_IMAGE_PATHS) > 0, 'No encontradas en `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","\n","print(\"> Modelo a usar: \", PATH_TO_CKPT)\n","print(\"> Cantidad de imágenes cargadas: \", len(TEST_IMAGE_PATHS))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XjQ4wph7MBuI","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Probar modelo con unas pocas imágenes de Validación\n","# ejecuta el modelo sobre las imágenes cargadas\n","%cd /content/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","from IPython.display import display\n","from collections import defaultdict\n","from io import StringIO\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n"," \n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","# función auxiliar para ejecutar el modelo\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n","\n","# procesa las imágenes cargadas\n","for image_path in TEST_IMAGE_PATHS:\n","\n","    print(\"\\n> \",  image_path, \": \")\n","\n","    # open file to process\n","    image = Image.open(image_path)\n","\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=8)\n","    \n","    # muestra la imagen con los objetos detectados\n","    display( Image.fromarray(image_np, 'RGB') )\n","    print(\" objetos detectados: \", output_dict['num_detections'])\n"],"execution_count":null,"outputs":[]}]}