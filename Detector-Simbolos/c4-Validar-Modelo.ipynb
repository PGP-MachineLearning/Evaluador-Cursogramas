{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"c4-Validar-Modelo.ipynb","provenance":[{"file_id":"1ZqC7qID9bdT9BL0hRfk9amySJidFq-7k","timestamp":1577829312762}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"pHefTSRioYTI"},"source":["# Lleva a cabo la Validación del Modelo Entrenado con TF2 comparando contra los objetos indicados en los XMLs correspondientes\n","Se basa en propuesta de https://towardsdatascience.com/evaluating-performance-of-an-object-detection-model-137a349c517b"]},{"cell_type":"markdown","metadata":{"id":"XKXKZbK5RPQZ"},"source":["0) Preparar ambiente e instalar paquetes:"]},{"cell_type":"code","metadata":{"id":"a3EvCh8J0Bex","cellView":"form"},"source":["#@title Clonar el repositorio de modelos de TF si no está ya disponible\n","import os\n","import pathlib\n","\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCD3yzfvRY8e","cellView":"form"},"source":["#@title Instalar el Object Detection API\n","# Nota: si dice que faltan librerías, ignorar (funciona bien igual) \n","#       sino volverlo a ejecutar esta celda para que reinistale y entonces dice todo \"successfully\"\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PEeuRn1wRjNz"},"source":["\n","1) Cargar librerías:"]},{"cell_type":"code","metadata":{"id":"MrgXb3574eAx","cellView":"form"},"source":["#@title Cargar Librerías\n","import os\n","import os.path\n","import sys\n","import numpy as np\n","import pandas as pd\n","from random import sample\n","\n","from IPython.display import Image, display\n","from PIL import Image as ImPIL\n","\n","import tensorflow as tf\n","from PIL import ImageColor\n","from PIL import ImageDraw\n","\n","import copy\n","import xml.etree.cElementTree as ET\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","import time\n","\n","print (\"Librerías cargadas.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Ly3kAM3qsLo"},"source":["2) Montar el Drive:"]},{"cell_type":"code","metadata":{"id":"LdUm8v20sawT","cellView":"form"},"source":["#@title Montar Google Drive\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieCbCWpM9-W9","cellView":"form"},"source":["#@title Definir configuración de directorios local en Google Drive\n","drive_path = '/content/gdrive/My Drive/GEMIS/objDetectionCursogramas' #@param {type:\"string\"}\n","drive_subdir_datos = '/Cursogramas' #@param {type:\"string\"}\n","drive_subdir_modelo = '/TF_model' #@param {type:\"string\"}\n","\n","data_dir_path = drive_path + drive_subdir_datos\n","model_drive_path = drive_path + drive_subdir_modelo\n","\n","print(\"Configuración de archivos definida\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6TSvP04bfOJG"},"source":["3) Cargar el modelo entrenado:"]},{"cell_type":"code","metadata":{"id":"Ue0RFAprfOeF","cellView":"form"},"source":["#@title Cargar el modelo de object detection entrenado y define funciones auxiliares\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","\n","# carga el modelo exportado \n","ModelObjDetEntrenado = model_drive_path + '/saved_model'\n","detection_model = tf.saved_model.load(str(ModelObjDetEntrenado))\n","print(\"\\nModelo objDetector cargado: [\", ModelObjDetEntrenado, \"]: \", detection_model)\n","\n","# archivo con lista de clases para reconocer \n","labelMapFile = model_drive_path + '/label_map.pbtxt'\n","\n","label_map = label_map_util.load_labelmap(labelMapFile)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map,\n","    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n","    use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)\n","print(\"\\nDefinición de Clases cargada: [\", labelMapFile, \"]: \", len(category_index))\n","\n","# Size, in inches, of the output images.\n","##IMAGE_SIZE = (12, 8)\n","##print(\"\\nIMAGE SIZE: \",  IMAGE_SIZE)\n","\n","## funciones auxiliares\n","\n","# función auxiliar para conversión de la imagen ( NO SE USA )\n","#def load_image_into_numpy_array(image):\n","#    (im_width, im_height) = image.size\n","#    return np.array(image.getdata()).reshape(\n","#        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# función auxiliar para procesar la imagen con el modelo\n","def run_inference_for_single_image(model, image_np):   \n","    # fuerza conversión a array por las dudas\n","    image_np = np.asarray(image_np) \n","    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","    input_tensor = tf.convert_to_tensor(image_np)\n","    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","    input_tensor = input_tensor[tf.newaxis,...]\n","\n","    # Run inference\n","    model_fn = model.signatures['serving_default']\n","    output_dict = model_fn(input_tensor)\n","\n","    # All outputs are batches tensors.\n","    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","    # We're only interested in the first num_detections.\n","    num_detections = int(output_dict.pop('num_detections'))\n","    output_dict = {key:value[0, :num_detections].numpy() \n","                  for key,value in output_dict.items()}\n","    output_dict['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n","    \n","    # Handle models with masks:\n","    if 'detection_masks' in output_dict:\n","      # Reframe the the bbox mask to the image size.\n","      detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                output_dict['detection_masks'], output_dict['detection_boxes'],\n","                image.shape[0], image.shape[1])      \n","      detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n","                                        tf.uint8)\n","      output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","      \n","    return output_dict\n","\n","# función auxiliar para mostrar resultados de procesar la imagen con el modelo\n","def plot_detections(image_np,\n","                    boxes,\n","                    classes,\n","                    scores,\n","                    category_index,\n","                    line_thickness = 8,\n","                    min_score = 0.8):\n","\n","    # genera una copia de la imagen\n","    image_np_with_annotations = image_np.copy()\n","\n","    # en la copia marca los objetos detectados\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np_with_annotations,\n","        boxes,\n","        classes,\n","        scores,\n","        category_index,\n","        use_normalized_coordinates=True,\n","        max_boxes_to_draw=100,\n","        line_thickness=line_thickness,\n","        min_score_thresh=min_score,\n","        agnostic_mode=False)\n","        \n","    # muestra la copia de la imagen con los objetos detectados\n","    display(ImPIL.fromarray(image_np_with_annotations))  \n","    #print(\"-- objetos detectados: \", len(classes), \"\\n\")  # siempre son 300\n","\n","print(\"\\nFunciones Auxiliares definidas.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uX-34hnJ3ub0"},"source":["4) Llevar a cabo la validación usando las imágenes y XML:"]},{"cell_type":"code","metadata":{"id":"4dym__JQCQ83","cellView":"form"},"source":["#@title Definir funciones auxiliares \n","\n","# función para cálculo de Intersection over Union (IoU) \n","def calc_IoU( gt_bbox, pred_bbox):\n","    '''\n","    This function takes the predicted bounding box and ground truth bounding box and \n","    return the IoU ratio\n","    '''\n","    x_topleft_gt, y_topleft_gt, x_bottomright_gt, y_bottomright_gt = gt_bbox\n","    x_topleft_p, y_topleft_p, x_bottomright_p, y_bottomright_p = pred_bbox\n","    \n","    if (x_topleft_gt > x_bottomright_gt) or (y_topleft_gt> y_bottomright_gt):\n","        raise AssertionError(\"Ground Truth Bounding Box is not correct\")\n","    if (x_topleft_p > x_bottomright_p) or (y_topleft_p> y_bottomright_p):\n","        raise AssertionError(\"Predicted Bounding Box is not correct\",x_topleft_p, x_bottomright_p,y_topleft_p,y_bottomright_gt)\n","        \n","         \n","    #if the GT bbox and predcited BBox do not overlap then iou=0\n","    if(x_bottomright_gt< x_topleft_p):\n","        # If bottom right of x-coordinate  GT  bbox is less than or above the top left of x coordinate of  the predicted BBox\n","        \n","        return 0.0\n","    if(y_bottomright_gt< y_topleft_p):  # If bottom right of y-coordinate  GT  bbox is less than or above the top left of y coordinate of  the predicted BBox\n","        \n","        return 0.0\n","    if(x_topleft_gt> x_bottomright_p): # If bottom right of x-coordinate  GT  bbox is greater than or below the bottom right  of x coordinate of  the predcited BBox\n","        \n","        return 0.0\n","    if(y_topleft_gt> y_bottomright_p): # If bottom right of y-coordinate  GT  bbox is greater than or below the bottom right  of y coordinate of  the predcited BBox\n","        \n","        return 0.0\n","    \n","    \n","    GT_bbox_area = (x_bottomright_gt -  x_topleft_gt + 1) * (  y_bottomright_gt -y_topleft_gt + 1)\n","    Pred_bbox_area =(x_bottomright_p - x_topleft_p + 1 ) * ( y_bottomright_p -y_topleft_p + 1)\n","    \n","    x_top_left =np.max([x_topleft_gt, x_topleft_p])\n","    y_top_left = np.max([y_topleft_gt, y_topleft_p])\n","    x_bottom_right = np.min([x_bottomright_gt, x_bottomright_p])\n","    y_bottom_right = np.min([y_bottomright_gt, y_bottomright_p])\n","    \n","    intersection_area = (x_bottom_right- x_top_left + 1) * (y_bottom_right-y_top_left  + 1)\n","    \n","    union_area = (GT_bbox_area + Pred_bbox_area - intersection_area)\n","   \n","    return intersection_area/union_area\n","\n","\n","# función para mostrar boxes en una imagen dada\n","def draw_box(draw, rangeObj, lineWidth, lineColor):  \n","\n","    draw.line([(rangeObj[0], rangeObj[1]), \n","                        (rangeObj[0], rangeObj[3]), \n","                        (rangeObj[2], rangeObj[3]), \n","                        (rangeObj[2], rangeObj[1]), \n","                        (rangeObj[0], rangeObj[1])], \n","                      width=lineWidth, fill=lineColor)\n","\n","# función para mostrar boxes de una lista objetos en una imagen dada\n","def draw_boxes_listObj(draw, listObj, lineWidth, lineColor):\n","  \n","    for obj in listObj:\n","        draw_box(draw, obj[2], lineWidth, lineColor)\n","\n","# función para mostrar métricas de los resultados\n","def mostrarMetricas(metricas, titulo):\n","\n","  print(\"\\n= \" + titulo + \":\")        \n","  print(\"                  Modelo \")\n","  print(\" XML   :       +          -   \")\n","  print(\"  +    :     %3d        %3d  \" % (metricas[posVP], metricas[posFN]) )\n","  print(\"  -    :     %3d        %3d  \" % (metricas[posFP], metricas[posVN]) )\n","\n","  # Cálculo de la Exactitud\n","  total = (metricas[posVP] + metricas[posFP] + metricas[posVN] + metricas[posFN])\n","  if total>0:\n","      print(\"= Exactitud: \", round(100*(metricas[posVP] + metricas[posVN])/total, 3))\n","\n","  # Cálculo de la Precisión\n","  total = (metricas[posVP] + metricas[posFP])\n","  if total>0:\n","      print(\"= Precisión: \",  round(100*metricas[posVP]/total,3))\n","\n","  # Cálculo de la Recuperación\n","  total = (metricas[posVP] + metricas[posFN])\n","  if total>0:\n","      print(\"= Recuperación: \", round(100*metricas[posVP]/total,3))\n","  \n","  print(\"\\n\")\n","  return\n","\n","print(\"Funciones auxiliares definidas\")   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qxwIEKoU-qVB","cellView":"form"},"source":["#@title Definir imágenes a utilizar\n","# define la carpeta donde están las imágenes para procesar\n","imagenes_utilizar = '/validation' #@param [ '/validation', '/Generados' ]\n","if imagenes_utilizar == '/validation':\n","  dirTestImg = data_dir_path + '/validation/images' \n","  dirTestXML = data_dir_path + '/validation/annotations' \n","elif imagenes_utilizar == '/Generados':\n","  dirTestImg = data_dir_path + '/Generados'\n","  dirTestXML = data_dir_path + '/Generados'\n","\n","# levanta los XML de validación para dirTestXML\n","process_FileNames = [ fn for fn in os.listdir( dirTestXML ) if fn.endswith('.xml') ]\n","print(\"> Imágenes/XML a probar: \", len(process_FileNames))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Q-1cIgNRQ6k","cellView":"form"},"source":["#@markdown ### Tomar una muestra de las imágenes (si es necesario o se quiere) { run: \"auto\" }\n","porcMuestraImagenesProcesar = 100  #@param {type:\"slider\", min:0, max:100, step:5}\n","if porcMuestraImagenesProcesar>0 and porcMuestraImagenesProcesar<100:\n","  cantProcesar = int(len(process_FileNames)*porcMuestraImagenesProcesar/100)\n","  if cantProcesar==0:\n","    cantProcesar = 1\n","  process_FileNames = sample(process_FileNames, cantProcesar)    \n","print(\"> Imágenes/XML a probar: \", len(process_FileNames))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tlt8GUjAcAVW","cellView":"form"},"source":["#@title Definir parámetros a utilizar { run: \"auto\" }\n","\n","# define minima probabilidad a usar\n","minimaProbabilidadObjectosDetectados = 90 #@param {type:\"slider\", min:1, max:100, step:1.0}\n","minProbObjDet = minimaProbabilidadObjectosDetectados / 100.\n","\n","# define si muestra detalle o no\n","muestraDetalleDebug = False  #@param {type:\"boolean\"}\n","muestraDetalleObjDetectadosEnImagen = False  #@param {type:\"boolean\"}\n","muestraDetalleComparacionEnImagen = \"Solo con Error\" #@param [\"Ninguna\", \"Solo con Error\", \"Todas\"]\n","muestraDetalleMetricasPorImagen = \"Solo con Error\" #@param [\"Ninguna\", \"Solo con Error\", \"Todas\"]\n","muestraDetalleMetricasPorClaseObjeto = True  #@param {type:\"boolean\"}\n","\n","# define parámetro Intersection over Union (IoU) \n","## si calc_IoU(r1, r2) ≥ coefIoU, se considera que se detectó el objecto correctamente, es Verdadero Positivo (VP)\n","## si calc_IoU(r1, r2) < coefIoU, se considera que se detectó el objecto con error, es Falso Positivo (FP)\n","## -> valor recomendado por defecto: 0,5 \n","## pero se usa menos para mejorar los resultados\n","coefIoU = 0.4 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","\n","print(\"Parámetros definidos\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nwwnSO_83y5D","cellView":"form"},"source":["#@title Realizar el Procesamiento de las Imágenes comparando contra XMLs\n","\n","# inicializa vector auxiliar para metricas y posiciones a usar\n","listaXMLConProblemas = []\n","cantXMLProcesados = 0\n","metricasGral = [ 0, 0, 0, 0]\n","posVP = 0\n","posVN = 1\n","posFP = 2\n","posFN = 3\n","\n","# inicializa diccionario auxiliar para metricas por tipo de caso generado\n","metricasGral_porTipoCaso = {}\n","\n","# inicializa vectores auxiliares para evaluación de objetos detectados\n","classObjModelo = []\n","classObjReal = []\n","\n","# auxiliar para calcular tiempos del modelo\n","auxSumaTiempo = 0\n","auxCantProc = 0\n","\n","# muestra parámetros\n","print(\"> Parámetros: \")\n","print(\"  minimaProbabilidadObjectosDetectados: \", minimaProbabilidadObjectosDetectados)\n","print(\"  coefIoU: \", coefIoU)\n","print(\"\\n\")\n","print(\"  muestraDetalleDebug: \", muestraDetalleDebug)\n","print(\"  muestraDetalleObjDetectadosEnImagen: \", muestraDetalleObjDetectadosEnImagen)\n","print(\"  muestraDetalleComparacionEnImagen: \", muestraDetalleComparacionEnImagen)\n","print(\"  muestraDetalleMetricasPorImagen: \", muestraDetalleMetricasPorImagen)\n","print(\"  muestraDetalleMetricasPorClaseObjeto: \", muestraDetalleMetricasPorClaseObjeto)\n","print(\"\\n\\n\\n\")\n","\n","# Procesa los XMLs de las imágenes \n","for xml_file in process_FileNames:\n","\n","    # inicializa vectores auxiliares\n","    listObjsXML = []\n","    listObjsDetModelo = []\n","    \n","    print(\"\\n------------------------------------------------------------------------------------------------------------\")\n","    cantXMLProcesados = cantXMLProcesados + 1\n","    print(\"<\", cantXMLProcesados, \"> \", xml_file, \": \")\n","\n","    # determina el tipo de archivo\n","    tipoCaso = \"\"\n","    if xml_file.startswith(\"da_\"):\n","      tipoCaso = \"DA\"\n","    else:\n","      tipoCaso = \"OR\"\n","    if xml_file.find(\"r-\")>=0 or xml_file.find(\"r.\")>=0:\n","      tipoCaso = tipoCaso + '_R'\n","    elif xml_file.find(\"s-\")>=0 or xml_file.find(\"s.\")>=0:\n","      tipoCaso = tipoCaso + '_S'\n","    else:\n","      tipoCaso = tipoCaso + '_N'\n","\n","    # carga la info del XML original\n","    et = ET.parse(dirTestXML + '/' + xml_file)\n","    element = et.getroot()\n","    element_objs = element.findall('object') \n","    element_filename = element.find('filename').text\n","\n","    imagenProcesar = os.path.join(dirTestImg, element_filename)\n","\n","    # controla que exista la imagen\n","    if not os.path.isfile(imagenProcesar):\n","      print(\"\\t -- No se encuentra la imagen \", imagenProcesar, \"!\\n\")\n","      # deja de procesar el XML y pasa al siguiente\n","      continue\n","\n","    # carga los elementos en el archivo XML original para generar el nuevo\n","    for element_obj in element_objs:\n","\n","        # obtiene la información actual de la imagen\n","        class_name = element_obj.find('name').text \n","\n","        # obtiene info del box actual\n","        obj_bbox = element_obj.find('bndbox')\n","        nuevoRangoIm = [ float(obj_bbox.find('xmin').text),\n","                        float(obj_bbox.find('ymin').text),\n","                        float(obj_bbox.find('xmax').text), \n","                        float(obj_bbox.find('ymax').text) ]\n","\n","        # si tiene invertidas las posiciones las corrige\n","        if nuevoRangoIm[0] > nuevoRangoIm[2]:\n","          auxnuevoRangoIm = nuevoRangoIm[2]\n","          nuevoRangoIm[2] = nuevoRangoIm[0]\n","          nuevoRangoIm[0] = auxnuevoRangoIm\n","        if nuevoRangoIm[1] > nuevoRangoIm[3]:\n","          auxnuevoRangoIm = nuevoRangoIm[3]\n","          nuevoRangoIm[3] = nuevoRangoIm[1]\n","          nuevoRangoIm[1] = auxnuevoRangoIm\n","\n","        # calcula un valor para poder ordenar las figuras de arriba a abajo y izquierda a derecha\n","        centroideIm = nuevoRangoIm[1]*100000+nuevoRangoIm[0]\n","\n","        # agrega a lista de objetos cargados del XML\n","        # controlando que no estuviera ya (para evitar duplicados)\n","        elObjXML = (centroideIm, class_name, nuevoRangoIm)        \n","        if elObjXML not in listObjsXML:\n","          listObjsXML.append( elObjXML )\n","\n","      # carga la imagen a procesar\n","    imageCargada = ImPIL.open(imagenProcesar) \n","\n","    # Convierte la imagen a escala de grises y luego a RGB \n","    # (para sacarle los colores que tuviera previamente y dejarlo con 3 canales de profundidad)\n","    imageCargada = imageCargada.convert('L')\n","    imageCargada = imageCargada.convert('RGB')\n","\n","    # obtiene el tamaño de la imagen\n","    imCargada_ancho, imCargada_alto = imageCargada.size\n","\n","    # convierte la imagen a un array \n","    image_np = np.array(imageCargada)\n","\n","    # Procesa el array de la imagen con el modelo cargado\n","    tiempoInicioModelo = time.time()\n","    output_dict = run_inference_for_single_image(detection_model, image_np)\n","    tiempoDemoraModelo = (time.time() - tiempoInicioModelo)\n","    if muestraDetalleDebug:\n","        print(\"\\n# Ejecutar el modelo demora \", tiempoDemoraModelo, \" segundos. \\n\")\n","    auxSumaTiempo = auxSumaTiempo  + tiempoDemoraModelo\n","    auxCantProc = auxCantProc  + 1\n","\n","    # procesa los objetos detectados\n","    for detClass, detBox, detScore in zip(  output_dict['detection_classes'], output_dict['detection_boxes'], output_dict['detection_scores'] ):\n","\n","        class_name = category_index[detClass]['name']\n","\n","        # como las coordenadas están normalizadas las debe convertir \n","        # teniendo en cuenta el tamaño de la imagen\n","        # además notar que vienen datas en otro orden\n","        # - detBox = (ini alto, ini ancho, fin alto, fin ancho)\n","        # - nuevoRangoIn = (ini ancho x1, ini alto y1, fin ancho x2, fin alto y2)    \n","        nuevoRangoIm = [detBox[1] * imCargada_ancho, \n","                        detBox[0] * imCargada_alto,\n","                        detBox[3] * imCargada_ancho,\n","                        detBox[2] * imCargada_alto]\n","\n","        # si el objeto detectado tiene un puntaje superior o igual al mínimo\n","        if detScore >= minProbObjDet:\n","\n","              # calcula un valor para poder ordenar las figuras de arriba a abajo y izquierda a derecha\n","              centroideIm = nuevoRangoIm[1]*100000+nuevoRangoIm[0]\n","\n","              # agrega a lista de objetos detectados por el modelo\n","              listObjsDetModelo.append( (centroideIm, class_name, nuevoRangoIm) )          \n","        else:\n","              if muestraDetalleDebug and detScore >= 0.4:\n","                print(\"-- Objeto descartado por bajo score: \", class_name, \"(\", detScore*100, \"%) en \", nuevoRangoIm)\n","\n","    # ordena por el centroide las dos listas\n","    listObjsXML = sorted(listObjsXML, key=lambda objDet: objDet[0])  \n","    listObjsDetModelo = sorted(listObjsDetModelo, key=lambda objDet: objDet[0])  \n","\n","    if muestraDetalleDebug:\n","        print(\"\\n- Objetos del XML:\")\n","        print(len(listObjsXML), \" : \",listObjsXML)\n","\n","        print(\"\\n- Objetos detectados por el Modelo:\")\n","        print(len(listObjsDetModelo), \" : \", listObjsDetModelo)\n","\n","    if muestraDetalleObjDetectadosEnImagen: \n","\n","        print(\"\\n- Muestra los objetos del XML y Detectados en la Imagen:\")\n","        # imagen auxiliar para mostrar recuadros de XML y modelo\n","        image_pil = copy.deepcopy(imageCargada.convert(\"RGB\"))\n","        draw = ImageDraw.Draw(image_pil)\n","        im_width, im_height = image_pil.size    \n","\n","        # genera los recuadros correspondientes del XML (en color verde)\n","        draw_boxes_listObj(draw, listObjsXML, 8, (0,255,0))\n","            \n","        # genera los recuadros correspondientes al Modelo (en color azul)\n","        draw_boxes_listObj(draw, listObjsDetModelo, 4, (0,0,255))\n","\n","        imMostrar = ImPIL.fromarray(np.array(image_pil), 'RGB')\n","        display( imMostrar )\n","        print(\" Nota colores:\")\n","        print(\"    Objetos definidos en el XML, cuadros en VERDE.\")\n","        print(\"    Objetos detectados por el Modelo, cuadros en AZUL.\")\n","        print(\"\\n\")\n","\n","    # Realiza la compración de los objetos definidos en el XML contra los detectados por el modelo\n","    if muestraDetalleDebug:\n","        print(\"\\n+ Realiza la Comparación: \")\n","\n","    resCompara = []\n","    auxlistObjsDetModelo = copy.copy(listObjsDetModelo)\n","\n","    # Busca el objeto del XML en la lista de objetos detectados por el Modelo\n","    # (para eso considera la ubicación y tipo de clase)\n","    for objXML in listObjsXML:\n","        i = -1\n","        noEnc = True\n","        while noEnc and i < (len(auxlistObjsDetModelo)-1):         \n","          i = i + 1\n","          \n","          # calcula la Intersection over Union (IoU) de los boxes\n","          objIoU = calc_IoU( objXML[2], auxlistObjsDetModelo[i][2] )\n","\n","          # si el IoU es casi perfecto, considera que es el objeto\n","          #if objIoU > 0.90: \n","          #  noEnc = False\n","          #else:\n","           #  analiza si tiene algo de superposición y es de la misma clase\n","          noEnc = not((objIoU > 0.1) and (objXML[1] == auxlistObjsDetModelo[i][1]))\n","\n","        if noEnc:\n","\n","           # Si no se encuentra objeto con misma ubicación y clase del XML\n","          if muestraDetalleDebug:\n","              print(objXML[1], \" no detectado por el Modelo con misma ubicación y clase \")\n","\n","          # registra que ese objeto no se encontró\n","          resCompara.append(  (objXML[1], -1, objXML[2], \"*\") )\n","\n","        else:\n","\n","          # Si encuentra objecto en misma ubicación y  clase del XML\n","          if muestraDetalleDebug:\n","              print(objXML[1], \": \", objIoU)\n","\n","          # regista que el objeto se encontró con su IoU\n","          resCompara.append(  (objXML[1], objIoU, auxlistObjsDetModelo[i][2], auxlistObjsDetModelo[i][1]) )\n","\n","          # saca el objeto de la lista auxiliar para que no se vuelva a usar\n","          auxlistObjsDetModelo.pop(i)\n","\n","    # Revisa los objetos detectados que no se utilizaron en la comparación anterior\n","    # para incluir en la comparación  \n","    #  objetos en la misma ubicación pero  con distinta clase\n","    #   u objetos detectados que no figuran en el XML\n","    if len(auxlistObjsDetModelo) > 0:\n","      if muestraDetalleDebug:\n","        print(\"\\n-Se intenta asociar con \", len(auxlistObjsDetModelo), \" objetos detectados del Modelo no utilizados\")\n","\n","      for objDet in auxlistObjsDetModelo:\n","\n","        # lo compara con los que no se puedieron detectar\n","        i = 0\n","        cont = True\n","        while cont and i < len(resCompara):\n","\n","            # sólo procesa es un objeto del XML no encontrado en Modelo \n","            if (resCompara[i][1] < 0):\n","                # calcula la Intersection over Union (IoU) de los boxes\n","                objIoU = calc_IoU( resCompara[i][2], objDet[2] )\n","\n","                if objIoU >= coefIoU:\n","                      # si están superpuestos se considera que se detectó pero le asignó mal la clase                    \n","                      resCompara[i] = (resCompara[i][0], objIoU, objDet[2], objDet[1] )                   \n","                      cont = False\n","\n","                      if muestraDetalleDebug:\n","                          print(\"--- Se rectifica objeto no detectado: \", resCompara[i])\n","            i = i + 1\n","\n","        if cont:\n","          # si no se utiliza, se agrega como objeto detectado de más\n","          resCompara.append(  (\"*\", 999, objDet[2], objDet[1]) )\n","\n","          if muestraDetalleDebug:\n","              print(\"--- Se agrega objeto detectado por Modelo de más: \", objDet[1])\n","\n","    if muestraDetalleDebug:\n","\n","        print(\"\\n+ Resultados de la Comparación:\")\n","        print( len(resCompara), \" : \", resCompara )\n","\n","\n","    # Realiza el cálculo de las Métricas de la Imagen considerando los resultados de la comparación\n","    ## ---------------------------------------------------------------------------------------------\n","    ## Nota los Verdadero Negativo (VN) se deberían calcular considerando el resto de la imagen que no tiene \n","    ## objetos, por lo que no es útil para Modelos de Object Detection y no se utiliza.\n","    ## ---------------------------------------------------------------------------------------------\n","    metricasImag = [ 0, 0, 0, 0]\n","\n","    hayErrorDetectado = False\n","    generaImagenComparacion = (muestraDetalleComparacionEnImagen != \"Ninguna\")\n","    if generaImagenComparacion:\n","      # imagen auxiliar para mostrar resultados comparación\n","      comp_image_pil = copy.deepcopy(imageCargada.convert(\"RGB\"))\n","      comp_draw = ImageDraw.Draw(comp_image_pil)\n","      im_width, im_height = comp_image_pil.size     \n","\n","    for resObj in resCompara:\n","\n","        if muestraDetalleMetricasPorClaseObjeto:\n","          # agrega en vectores auxiliares para hacer la evaluación por clase\n","          classObjReal.append( resObj[0] )\n","          classObjModelo.append( resObj[3] )\n","\n","        if (resObj[0] == resObj[3]) and (resObj[1] >= coefIoU):\n","\n","            # Objeto de misma Clase entre XML y Modelo con IoU ≥ coefIoU -> Verdadero Positivo (VP)\n","            posM = posVP\n","            if generaImagenComparacion:            \n","              draw_box(comp_draw, resObj[2], 4, (0,255,0)) # cuadros Verdes\n","\n","        elif resObj[1] < 0:\n","\n","            # Objecto del XML no encontrado en Modelo -> Falso Negativo (FN)\n","            posM = posFN\n","            hayErrorDetectado = True\n","            if generaImagenComparacion:\n","              draw_box(comp_draw, resObj[2], 4, (255,0,0)) # cuadros Rojos\n","\n","        else:\n","\n","            # Objeto de misma Clase entre XML y Modelo con calc_IoU(r1, r2) < coefIoU -> Falso Positivo (FP)\n","            # Objeto de distinta Clase entre XML y Modelo con calc_IoU(r1, r2) ≥ coefIoU -> Falso Positivo (FP)\n","            # Objeto detectado por el Modelo que no aparece en el Modelo -> Falso Positivo (FP)\n","            posM = posFP\n","            hayErrorDetectado = True\n","            if generaImagenComparacion:            \n","              if resObj[1] == 999:\n","                draw_box(comp_draw, resObj[2], 4, (255,155,255)) # cuadros Rosa\n","              elif (resObj[0] != resObj[3]):\n","                draw_box(comp_draw, resObj[2], 4, (255,255,0)) # cuadros Amarillo\n","              else:\n","                draw_box(comp_draw, resObj[2], 4, (255,155,0)) # cuadros Naranja\n","\n","        metricasImag[posM] = metricasImag[posM] + 1\n","\n","    # Agrega a la métrica general y detalle por tipo de imagen    \n","    if not ( tipoCaso in metricasGral_porTipoCaso ):\n","      # inicaliza la matriz por tipo de caso si corresponde\n","      metricasGral_porTipoCaso[tipoCaso] = [ 0, 0, 0, 0] \n","    for i in range(4):\n","      # actualiza matriz general\n","      metricasGral[i] = metricasGral[i] + metricasImag[i]\n","      # actualiza matriz general por tipo de caso\n","      metricasGral_porTipoCaso[tipoCaso][i] = metricasGral_porTipoCaso[tipoCaso][i] + metricasImag[i]\n","\n","    if hayErrorDetectado: \n","          listaXMLConProblemas.append( xml_file )\n","    \n","    if generaImagenComparacion and ( (muestraDetalleComparacionEnImagen == \"Todas\") or ( hayErrorDetectado and (muestraDetalleComparacionEnImagen == \"Solo con Error\") ) ):\n","\n","        imMostrar = ImPIL.fromarray(np.array(comp_image_pil), 'RGB')\n","        display( imMostrar )\n","        print(\" Nota colores:\")\n","        print(\"     Verdaderos Positivos (igual ubicación y misma clase): cuadros en VERDE.\")\n","        print(\"     Falsos Positivos (misma ubicación y distinta clase): cuadro en  AMARILLO\")\n","        print(\"     Falsos Positivos (diferencia de ubicación y misma clase): cuadros en NARANJA\")\n","        print(\"     Falsos Positivos (detectados de más por el Modelo): cuadros en ROSA \")        \n","        print(\"     Falsos Negativos (no detectado por el Modelo): cuadros en ROJO.\")\n","\n","    if ( (muestraDetalleMetricasPorImagen == \"Todas\") or ( hayErrorDetectado and (muestraDetalleMetricasPorImagen == \"Solo con Error\") ) ):\n","        mostrarMetricas(metricasImag, \"Matriz de Confusión para la Imagen\" )    \n","    else:\n","        if hayErrorDetectado: \n","            print(\" -- se detecta al menos un error!\")\n","        else:\n","            print(\" ++ sin error detectado.\")\n","\n","print(\"\\n == VALIDACIÓN FINALIZADA ==\")\n","print(\" XMLs revisados: \", cantXMLProcesados)\n","\n","auxLista = '['\n","if len(listaXMLConProblemas)>0:\n","  for f in listaXMLConProblemas:\n","      auxLista = auxLista + \" '\" + f + \"',\"\n","  auxLista = auxLista[:len(auxLista)-1] \n","auxLista = auxLista + ']'    \n","print(\"\\n \", len(listaXMLConProblemas),\" XMLs con problemas detectados: \\n\\t\", auxLista, \"\\n\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wx4uQ9KeHJiL","cellView":"form"},"source":["#@title Mostrar las Métricas Generales\r\n","print(\"\\n\\n===========================================================================================================\\n\")\r\n","mostrarMetricas(metricasGral, \"Matriz de Confusión General del Modelo Entrenado\" )\r\n","# Muestra tiempo de ejecución promedio\r\n","if auxCantProc>0:\r\n","  print(\"\\n\\n# Ejecutar el modelo demora en promedio \",  (auxSumaTiempo/auxCantProc), \" segundos. \\n\\n\")\r\n","print(\"\\n===========================================================================================================\\n\")\r\n","\r\n","# muestra reporte de clasificación\r\n","if len(classObjReal)>0 and len(classObjModelo)>0:\r\n","  print(\"\\n Reporte de Clasificación por Clase del Modelo Entrenado: \")\r\n","  print(classification_report(y_true=classObjReal, y_pred=classObjModelo))\r\n","\r\n","print(\"\\n===========================================================================================================\\n\")\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u7hTVgInvfLo","cellView":"form"},"source":["#@title Mostrar la Matriz de Confusión General por Clase (scrolleable)\n","\n","###pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n","# muestra matriz de confusion por clase\n","CLASSES = list(set(classObjReal + classObjModelo)) \n","if len(CLASSES)==0:\n","  print(\"No se definieron los datos para generar matriz!\")\n","  cmtx = \"\"\n","else:   \n","  print('\\nMatriz de Confusión por Clase del Modelo Entrenado: ')\n","  cm = confusion_matrix(y_true=classObjReal, y_pred=classObjModelo, labels=CLASSES)\n","  cmtx = pd.DataFrame(\n","      cm, \n","      index=['r:{:}'.format(x) for x in CLASSES], \n","      columns=['m:{:}'.format(x) for x in CLASSES]\n","    )\n","  ###print(cmtx)\n","cmtx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S1bbbV6GAeaY","cellView":"form"},"source":["#@title Mostrar las Matrices de Confusión por Tipo de Caso\r\n","\r\n","arTiposCasos = list(metricasGral_porTipoCaso.keys())\r\n","arTiposCasos.sort()\r\n","# recorre por tipo de caso evaluado\r\n","for tipoCaso in arTiposCasos:\r\n","  titulo = \"Matriz de Confusión del Modelo Entrenado para imágenes \"\r\n","  if tipoCaso[0:1] == \"DA\":\r\n","    titulo = titulo + \"CON DA\"\r\n","  else:\r\n","    titulo = titulo + \"SIN DA\"\r\n","  if tipoCaso[3] == \"R\":\r\n","    titulo = titulo + \"y TAMAÑO REDUCIDO de TRANSICIONES\"\r\n","  elif tipoCaso[3] == \"S\":\r\n","    titulo = titulo + \"y SIN TRANSICIONES\"\r\n","  else:\r\n","    titulo = titulo + \"y TAMAÑO NORMAL de TRANSICIONES\"\r\n","  titulo = titulo + \" [\"+tipoCaso+\"]:\"\r\n","  print(\"\\n-----------------------------------------------------------------------------------------------------------\\n\")\r\n","  mostrarMetricas(metricasGral_porTipoCaso[tipoCaso], titulo)\r\n","\r\n","print(\"\\n-----------------------------------------------------------------------------------------------------------\\n\")\r\n"],"execution_count":null,"outputs":[]}]}