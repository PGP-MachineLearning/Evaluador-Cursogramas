{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"c3a-TensorFlow-Check-Detectar-Objetos.ipynb","provenance":[{"file_id":"1ZqC7qID9bdT9BL0hRfk9amySJidFq-7k","timestamp":1577829312762}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"pHefTSRioYTI","colab_type":"text"},"source":["# Lleva a cabo una Prueba Inicial de Validación del Modelo Entrenado viendo los objetos detectados en las imágenes de validación"]},{"cell_type":"markdown","metadata":{"id":"XKXKZbK5RPQZ","colab_type":"text"},"source":["0) Preparar ambiente e instalar paquetes:"]},{"cell_type":"code","metadata":{"id":"a3EvCh8J0Bex","colab_type":"code","colab":{}},"source":["# nota se debe indicar la versión 1 de TF para compatibilidad del código\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCD3yzfvRY8e","colab_type":"code","cellView":"form","colab":{}},"source":["#@title baja e instala los parquetes de 'Object Detection' de Tensor Flow a utilizar en el disco temporal de Colab (demora un ratito)\n","\n","!pip install tf_slim\n","\n","%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","model_dir = 'training/'\n","\n","!python object_detection/builders/model_builder_test.py\n","\n","os.environ['PYTHONPATH'] += ':/content/models/research/object_detection:/content/models/research/slim/object_detection'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PEeuRn1wRjNz","colab_type":"text"},"source":["\n","1) Cargar librerías:"]},{"cell_type":"code","metadata":{"id":"MrgXb3574eAx","colab_type":"code","colab":{}},"source":["import os\n","import os.path\n","import sys\n","import numpy as np\n","\n","from IPython.display import Image, display\n","from PIL import Image as ImPIL\n","\n","print (\"Librerías cargadas.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Ly3kAM3qsLo","colab_type":"text"},"source":["2) Montar el Drive:"]},{"cell_type":"code","metadata":{"id":"LdUm8v20sawT","colab_type":"code","colab":{}},"source":["# monta Google Drive:\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieCbCWpM9-W9","colab_type":"code","colab":{}},"source":["# configuración de directorios local en Google Drive\n","drive_path = '/content/gdrive/My Drive/GEMIS/objDetectionCursogramas'\n","data_dir_path = drive_path + '/Cursogramas'\n","\n","print(\"Configuración de archivos definida\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6TSvP04bfOJG","colab_type":"text"},"source":["3) Cargar el modelo entrenado:"]},{"cell_type":"code","metadata":{"id":"Ue0RFAprfOeF","colab_type":"code","cellView":"form","colab":{}},"source":["#@title carga el modelo de object detection entrenado\n","\n","# path donde está el modelo exportado\n","ModelObjDetEntrenado = drive_path + '/TF_model/frozen_inference_graph.pb'\n","\n","# archivo con lista de etiquetas para mostrar \n","labelMapFile = data_dir_path + '/label_map.pbtxt'\n","\n","# se debe ubicar en el directorio correspondiente\n","%cd /content/models/research/object_detection\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n"," \n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(ModelObjDetEntrenado, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","label_map = label_map_util.load_labelmap(labelMapFile)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=90, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","# función auxiliar para ejecutar el modelo\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n","\n","print(\"Modelo objDetector cargado: [\", ModelObjDetEntrenado, \"], [\", labelMapFile, \"] \")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uX-34hnJ3ub0","colab_type":"text"},"source":["4) Llevar a cabo la detección de objetos sobre las imágenes de validación:"]},{"cell_type":"code","metadata":{"id":"qxwIEKoU-qVB","colab_type":"code","colab":{}},"source":["# define la carpeta donde están las imágenes para procesar\n","\n","#dirTest = data_dir_path + '/validation/images' \n","#dirTestXML = data_dir_path + '/validation/annotations' \n","dirTest = data_dir_path + '/Generados' \n","dirTestXML = data_dir_path + '/Generados' \n","\n","\n","# levanta las imágenes de prueba para procesar\n","process_FileNames = [ fn for fn in os.listdir( dirTest ) if fn.endswith('.png') or fn.endswith('.jpg') ]\n","print(\"> Imágenes a probar: \", len(process_FileNames))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvoNuTau2IKw","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Toma una muestra de las imágenes (si es necesario o se quiere) { run: \"auto\" }\n","\n","porcMuestraImagenesProcesar = 100  #@param {type:\"slider\", min:0, max:100, step:5}\n","if porcMuestraImagenesProcesar>0 and porcMuestraImagenesProcesar<100:\n","  cantProcesar = int(len(process_FileNames)*porcMuestraImagenesProcesar/100)\n","  if cantProcesar==0:\n","    cantProcesar = 1\n","  process_FileNames = process_FileNames[:cantProcesar]\n","print(\"> Imágenes/XML a probar: \", len(process_FileNames))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nwwnSO_83y5D","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Muestra los objetos detectados en las imágenes\n","\n","# define minima probabilidad a usar\n","minimaProbabilidadObjectDetection = 95 #@param {type:\"slider\", min:1, max:100, step:1.0}\n","minProbObjDet = minimaProbabilidadObjectDetection / 100.0\n","\n","# define si muestra detalle o no\n","muestraDetalleSubImagenes = False #@param {type:\"boolean\"}\n","\n","# procesa las imágenes \n","for fn in process_FileNames:\n","\n","  # define archivo a procesar y generar\n","  imagenProcesar = dirTest + '/' + fn\n","\n","  print(\"\\n> \", imagenProcesar, \": \")\n","  \n","  # open file to process\n","  imageCargada = ImPIL.open(imagenProcesar) \n","  imCargada_ancho, imCargada_alto = imageCargada.size\n","\n","  # the array based representation of the image will be used later in order to prepare the\n","  # result image with boxes and labels on it.\n","  image_np = load_image_into_numpy_array(imageCargada)\n","\n","  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","  image_np_expanded = np.expand_dims(image_np, axis=0)\n","\n","  # Actual detection.\n","  output_dict = run_inference_for_single_image(image_np, detection_graph)\n","\n","  # Visualization of the results of a detection.\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks'),\n","      use_normalized_coordinates=True,\n","      line_thickness=8)\n","\n","  # muestra la imagen con los objetos detectados\n","  display( ImPIL.fromarray(image_np, 'RGB') )\n","\n","  if muestraDetalleSubImagenes:   \n","\n","      # procesa los objetos detectados\n","      for detClass, detBox, detScore in zip(  output_dict['detection_classes'], output_dict['detection_boxes'], output_dict['detection_scores'] ):\n","\n","          # si el objeto detectado tiene un puntaje superior o igual al mínimo\n","          if detScore>=minProbObjDet:\n","\n","            # como las coordenadas están normalizadas las debe convertir \n","            # teniendo en cuenta el tamaño de la imagen\n","            # además notar que vienen datas en otro orden\n","            # - detBox = (ini alto, ini ancho, fin alto, fin ancho)\n","            # - nuevoRangoIn = (ini ancho, ini alto, fin ancho, fin alto)    \n","            nuevoRangoIm = (detBox[1] * imCargada_ancho, \n","                            detBox[0] * imCargada_alto,\n","                            detBox[3] * imCargada_ancho,\n","                            detBox[2] * imCargada_alto) \n","            centroideIm = (nuevoRangoIm[2]-nuevoRangoIm[0]/2) \n","\n","            # extrae la subimage de acuerdo al área indicada por el detector        \n","            imDetObj = imageCargada.crop(nuevoRangoIm )\n","    \n","            # muestra la sub-imagen\n","            print(\"\\n\")\n","            display( imDetObj )\n","\n","            # muestra resultados\n","            print(\"    - detecta \", detClass, \" : \", detScore*100, \"% : \", detBox, \"con centroide: \", centroideIm)\n","\n"],"execution_count":null,"outputs":[]}]}