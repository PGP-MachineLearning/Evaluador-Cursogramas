{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"c3b-TensorFlow-Validar-Modelo.ipynb","provenance":[{"file_id":"1ZqC7qID9bdT9BL0hRfk9amySJidFq-7k","timestamp":1577829312762}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"pHefTSRioYTI","colab_type":"text"},"source":["# Lleva a cabo la Validación del Modelo Entrenado comparando contra los objetos indicados en los XMLs correspondientes\n","Se basa en propuesta de https://towardsdatascience.com/evaluating-performance-of-an-object-detection-model-137a349c517b"]},{"cell_type":"markdown","metadata":{"id":"XKXKZbK5RPQZ","colab_type":"text"},"source":["0) Preparar ambiente e instalar paquetes:"]},{"cell_type":"code","metadata":{"id":"a3EvCh8J0Bex","colab_type":"code","colab":{}},"source":["# nota se debe indicar la versión 1 de TF para compatibilidad del código\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCD3yzfvRY8e","colab_type":"code","cellView":"form","colab":{}},"source":["#@title baja e instala los parquetes de 'Object Detection' de Tensor Flow a utilizar en el disco temporal de Colab (demora un ratito)\n","!pip install tf_slim\n","\n","%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","model_dir = 'training/'\n","\n","!python object_detection/builders/model_builder_test.py\n","\n","os.environ['PYTHONPATH'] += ':/content/models/research/object_detection:/content/models/research/slim/object_detection'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PEeuRn1wRjNz","colab_type":"text"},"source":["\n","1) Cargar librerías:"]},{"cell_type":"code","metadata":{"id":"MrgXb3574eAx","colab_type":"code","colab":{}},"source":["import os\n","import os.path\n","import sys\n","import numpy as np\n","import pandas as pd\n","\n","from IPython.display import Image, display\n","from PIL import Image as ImPIL\n","\n","import tensorflow as tf\n","from PIL import ImageColor\n","from PIL import ImageDraw\n","\n","import copy\n","import xml.etree.cElementTree as ET\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","print (\"Librerías cargadas.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Ly3kAM3qsLo","colab_type":"text"},"source":["2) Montar el Drive:"]},{"cell_type":"code","metadata":{"id":"LdUm8v20sawT","colab_type":"code","colab":{}},"source":["# monta Google Drive:\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieCbCWpM9-W9","colab_type":"code","colab":{}},"source":["# configuración de directorios local en Google Drive\n","drive_path = '/content/gdrive/My Drive/GEMIS/objDetectionCursogramas'\n","data_dir_path = drive_path + '/Cursogramas'\n","\n","print(\"Configuración de archivos definida\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6TSvP04bfOJG","colab_type":"text"},"source":["3) Cargar el modelo entrenado:"]},{"cell_type":"code","metadata":{"id":"Ue0RFAprfOeF","colab_type":"code","cellView":"form","colab":{}},"source":["#@title carga el modelo de object detection entrenado\n","\n","# path donde está el modelo exportado\n","ModelObjDetEntrenado = drive_path + '/TF_model/frozen_inference_graph.pb'\n","\n","# archivo con lista de etiquetas para mostrar \n","labelMapFile = data_dir_path + '/label_map.pbtxt'\n","\n","# se debe ubicar en el directorio correspondiente\n","%cd /content/models/research/object_detection\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n"," \n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(ModelObjDetEntrenado, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","label_map = label_map_util.load_labelmap(labelMapFile)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=90, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","# función auxiliar para ejecutar el modelo\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n","\n","print(\"Modelo objDetector-Carteles cargado: [\", ModelObjDetEntrenado, \"], [\", labelMapFile, \"] \")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uX-34hnJ3ub0","colab_type":"text"},"source":["4) Llevar a cabo la validación usando las imágenes y XML:"]},{"cell_type":"code","metadata":{"id":"4dym__JQCQ83","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Define funciones auxiliares \n","\n","# función para cálculo de Intersection over Union (IoU) \n","def calc_IoU( gt_bbox, pred_bbox):\n","    '''\n","    This function takes the predicted bounding box and ground truth bounding box and \n","    return the IoU ratio\n","    '''\n","    x_topleft_gt, y_topleft_gt, x_bottomright_gt, y_bottomright_gt = gt_bbox\n","    x_topleft_p, y_topleft_p, x_bottomright_p, y_bottomright_p = pred_bbox\n","    \n","    if (x_topleft_gt > x_bottomright_gt) or (y_topleft_gt> y_bottomright_gt):\n","        raise AssertionError(\"Ground Truth Bounding Box is not correct\")\n","    if (x_topleft_p > x_bottomright_p) or (y_topleft_p> y_bottomright_p):\n","        raise AssertionError(\"Predicted Bounding Box is not correct\",x_topleft_p, x_bottomright_p,y_topleft_p,y_bottomright_gt)\n","        \n","         \n","    #if the GT bbox and predcited BBox do not overlap then iou=0\n","    if(x_bottomright_gt< x_topleft_p):\n","        # If bottom right of x-coordinate  GT  bbox is less than or above the top left of x coordinate of  the predicted BBox\n","        \n","        return 0.0\n","    if(y_bottomright_gt< y_topleft_p):  # If bottom right of y-coordinate  GT  bbox is less than or above the top left of y coordinate of  the predicted BBox\n","        \n","        return 0.0\n","    if(x_topleft_gt> x_bottomright_p): # If bottom right of x-coordinate  GT  bbox is greater than or below the bottom right  of x coordinate of  the predcited BBox\n","        \n","        return 0.0\n","    if(y_topleft_gt> y_bottomright_p): # If bottom right of y-coordinate  GT  bbox is greater than or below the bottom right  of y coordinate of  the predcited BBox\n","        \n","        return 0.0\n","    \n","    \n","    GT_bbox_area = (x_bottomright_gt -  x_topleft_gt + 1) * (  y_bottomright_gt -y_topleft_gt + 1)\n","    Pred_bbox_area =(x_bottomright_p - x_topleft_p + 1 ) * ( y_bottomright_p -y_topleft_p + 1)\n","    \n","    x_top_left =np.max([x_topleft_gt, x_topleft_p])\n","    y_top_left = np.max([y_topleft_gt, y_topleft_p])\n","    x_bottom_right = np.min([x_bottomright_gt, x_bottomright_p])\n","    y_bottom_right = np.min([y_bottomright_gt, y_bottomright_p])\n","    \n","    intersection_area = (x_bottom_right- x_top_left + 1) * (y_bottom_right-y_top_left  + 1)\n","    \n","    union_area = (GT_bbox_area + Pred_bbox_area - intersection_area)\n","   \n","    return intersection_area/union_area\n","\n","\n","# función para mostrar boxes en una imagen dada\n","def draw_box(draw, rangeObj, lineWidth, lineColor):  \n","\n","    draw.line([(rangeObj[0], rangeObj[1]), \n","                        (rangeObj[0], rangeObj[3]), \n","                        (rangeObj[2], rangeObj[3]), \n","                        (rangeObj[2], rangeObj[1]), \n","                        (rangeObj[0], rangeObj[1])], \n","                      width=lineWidth, fill=lineColor)\n","\n","# función para mostrar boxes de una lista objetos en una imagen dada\n","def draw_boxes_listObj(draw, listObj, lineWidth, lineColor):\n","  \n","    for obj in listObj:\n","        draw_box(draw, obj[2], lineWidth, lineColor)\n","\n","print(\"Funciones auxiliares definidas\")   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qxwIEKoU-qVB","colab_type":"code","colab":{}},"source":["# define la carpeta donde están las imágenes para procesar\n","\n","#dirTestImg = data_dir_path + '/validation/images' \n","#dirTestXML = data_dir_path + '/validation/annotations' \n","\n","dirTestImg = data_dir_path + '/Generados' \n","dirTestXML = data_dir_path + '/Generados' \n","\n","# levanta los XML de validación para dirTestXML\n","process_FileNames = [ fn for fn in os.listdir( dirTestXML ) if fn.endswith('.xml') ]\n","print(\"> Imágenes/XML a probar: \", len(process_FileNames))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Q-1cIgNRQ6k","colab_type":"code","cellView":"form","colab":{}},"source":["#@markdown ### Toma una muestra de las imágenes (si es necesario o se quiere) { run: \"auto\" }\n","porcMuestraImagenesProcesar = 5  #@param {type:\"slider\", min:0, max:100, step:5}\n","if porcMuestraImagenesProcesar>0 and porcMuestraImagenesProcesar<100:\n","  cantProcesar = int(len(process_FileNames)*porcMuestraImagenesProcesar/100)\n","  if cantProcesar==0:\n","    cantProcesar = 1\n","  process_FileNames = process_FileNames[:cantProcesar]\n","print(\"> Imágenes/XML a probar: \", len(process_FileNames))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tlt8GUjAcAVW","colab_type":"code","cellView":"form","colab":{}},"source":["#@title define parámetros a utilizar { run: \"auto\" }\n","\n","# define minima probabilidad a usar\n","minimaProbabilidadObjectosDetectados = 90 #@param {type:\"slider\", min:1, max:100, step:1.0}\n","minProbObjDet = minimaProbabilidadObjectosDetectados / 100.\n","\n","# define si muestra detalle o no\n","muestraDetalleDebug = False  #@param {type:\"boolean\"}\n","muestraDetalleObjDetectadosEnImagen = False  #@param {type:\"boolean\"}\n","muestraDetalleComparacionEnImagen = \"Solo con Error\" #@param [\"Ninguna\", \"Solo con Error\", \"Todas\"]\n","muestraDetalleMetricasPorImagen = \"Solo con Error\" #@param [\"Ninguna\", \"Solo con Error\", \"Todas\"]\n","muestraDetalleMetricasPorClaseObjeto = True  #@param {type:\"boolean\"}\n","\n","# define parámetro Intersection over Union (IoU) \n","## si calc_IoU(r1, r2) ≥ coefIoU, se considera que se detectó el objecto correctamente, es Verdadero Positivo (VP)\n","## si calc_IoU(r1, r2) < coefIoU, se considera que se detectó el objecto con error, es Falso Positivo (FP)\n","## -> valor recomendado por defecto: 0,5 \n","## pero se usa menos para mejorar los resultados\n","coefIoU = 0.4 #@param {type:\"slider\", min:0.1, max:1, step:0.1}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nwwnSO_83y5D","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Realizar la Validación del Modelo\n","# inicializa vector auxiliar para metricas y posiciones a usar\n","cantXMLProcesados = 0\n","metricasGral = [ 0, 0, 0, 0]\n","posVP = 0\n","posVN = 1\n","posFP = 2\n","posFN = 3\n","\n","# inicializa vectores auxiliares para evaluación de objetos detectados\n","classObjModelo = []\n","classObjReal = []\n","\n","# muestra parámetros\n","print(\"> Parámetros: \")\n","print(\"  minimaProbabilidadObjectosDetectados: \", minimaProbabilidadObjectosDetectados)\n","print(\"  coefIoU: \", coefIoU)\n","print(\"\\n\")\n","print(\"  muestraDetalleDebug: \", muestraDetalleDebug)\n","print(\"  muestraDetalleObjDetectadosEnImagen: \", muestraDetalleObjDetectadosEnImagen)\n","print(\"  muestraDetalleComparacionEnImagen: \", muestraDetalleComparacionEnImagen)\n","print(\"  muestraDetalleMetricasPorImagen: \", muestraDetalleMetricasPorImagen)\n","print(\"  muestraDetalleMetricasPorClaseObjeto: \", muestraDetalleMetricasPorClaseObjeto)\n","print(\"\\n\\n\\n\")\n","\n","# Procesa los XMLs de las imágenes \n","for xml_file in process_FileNames:\n","\n","    # inicializa vectores auxiliares\n","    listObjsXML = []\n","    listObjsDetModelo = []\n","    \n","    print(\"\\n------------------------------------------------------------------------------------------------------------\")\n","    cantXMLProcesados = cantXMLProcesados + 1\n","    print(\"<\", cantXMLProcesados, \"> \", xml_file, \": \")\n","\n","    # carga la info del XML original\n","    et = ET.parse(dirTestXML + '/' + xml_file)\n","    element = et.getroot()\n","    element_objs = element.findall('object') \n","    element_filename = element.find('filename').text\n","\n","    imagenProcesar = os.path.join(dirTestImg, element_filename)\n","\n","    # carga los elementos en el archivo XML original para generar el nuevo\n","    for element_obj in element_objs:\n","\n","        # obtiene la información actual de la imagen\n","        class_name = element_obj.find('name').text \n","\n","        # obtiene info del box actual\n","        obj_bbox = element_obj.find('bndbox')\n","        nuevoRangoIm = [ float(obj_bbox.find('xmin').text),\n","                        float(obj_bbox.find('ymin').text),\n","                        float(obj_bbox.find('xmax').text), \n","                        float(obj_bbox.find('ymax').text) ]\n","\n","        # calcula un valor para poder ordenar las figuras de arriba a abajo y izquierda a derecha\n","        centroideIm = nuevoRangoIm[1]*100000+nuevoRangoIm[0]\n","\n","        # agrega a lista de objetos cargados del XML\n","        listObjsXML.append( (centroideIm, class_name, nuevoRangoIm) )\n","\n","    # carga la imagen a procesar\n","    imageCargada = ImPIL.open(imagenProcesar) \n","\n","    # Convierte la imagen a escala de grises y luego a RGB \n","    # (para sacarle los colores que tuviera previamente y dejarlo con 3 canales de profundidad)\n","    imageCargada = imageCargada.convert('L')\n","    imageCargada = imageCargada.convert('RGB')\n","\n","    imCargada_ancho, imCargada_alto = imageCargada.size\n","\n","    # prepara la imagen cargada\n","    image_np = load_image_into_numpy_array(imageCargada)\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","\n","    # ejecuta el modelo\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","\n","    # procesa los objetos detectados\n","    for detClass, detBox, detScore in zip(  output_dict['detection_classes'], output_dict['detection_boxes'], output_dict['detection_scores'] ):\n","\n","        # si el objeto detectado tiene un puntaje superior o igual al mínimo\n","        if detScore >= minProbObjDet:\n","\n","              class_name = category_index[detClass]['name']\n","\n","              # como las coordenadas están normalizadas las debe convertir \n","              # teniendo en cuenta el tamaño de la imagen\n","              # además notar que vienen datas en otro orden\n","              # - detBox = (ini alto, ini ancho, fin alto, fin ancho)\n","              # - nuevoRangoIn = (ini ancho x1, ini alto y1, fin ancho x2, fin alto y2)    \n","              nuevoRangoIm = [detBox[1] * imCargada_ancho, \n","                              detBox[0] * imCargada_alto,\n","                              detBox[3] * imCargada_ancho,\n","                              detBox[2] * imCargada_alto]\n","\n","              # calcula un valor para poder ordenar las figuras de arriba a abajo y izquierda a derecha\n","              centroideIm = nuevoRangoIm[1]*100000+nuevoRangoIm[0]\n","\n","              # agrega a lista de objetos detectados por el modelo\n","              listObjsDetModelo.append( (centroideIm, class_name, nuevoRangoIm) )          \n","    \n","    # ordena por el centroide las dos listas\n","    listObjsXML = sorted(listObjsXML, key=lambda objDet: objDet[0])  \n","    listObjsDetModelo = sorted(listObjsDetModelo, key=lambda objDet: objDet[0])  \n","\n","    if muestraDetalleDebug:\n","        print(\"\\n- Objetos del XML:\")\n","        print(len(listObjsXML), \" : \",listObjsXML)\n","\n","        print(\"\\n- Objetos detectados por el Modelo:\")\n","        print(len(listObjsDetModelo), \" : \", listObjsDetModelo)\n","\n","    if muestraDetalleObjDetectadosEnImagen: \n","\n","        print(\"\\n- Muestra los objetos del XML y Detectados en la Imagen:\")\n","        # imagen auxiliar para mostrar recuadros de XML y modelo\n","        image_pil = copy.deepcopy(imageCargada.convert(\"RGB\"))\n","        draw = ImageDraw.Draw(image_pil)\n","        im_width, im_height = image_pil.size    \n","\n","        # genera los recuadros correspondientes del XML (en color verde)\n","        draw_boxes_listObj(draw, listObjsXML, 8, (0,255,0))\n","            \n","        # genera los recuadros correspondientes al Modelo (en color azul)\n","        draw_boxes_listObj(draw, listObjsDetModelo, 4, (0,0,255))\n","\n","        imMostrar = ImPIL.fromarray(np.array(image_pil), 'RGB')\n","        display( imMostrar )\n","        print(\" Nota colores:\")\n","        print(\"    Objetos definidos en el XML, cuadros en VERDE.\")\n","        print(\"    Objetos detectados por el Modelo, cuadros en AZUL.\")\n","        print(\"\\n\")\n","\n","    # Realiza la compración de los objetos definidos en el XML contra los detectados por el modelo\n","    if muestraDetalleDebug:\n","        print(\"\\n+ Realiza la Comparación: \")\n","\n","    resCompara = []\n","    auxlistObjsDetModelo = copy.copy(listObjsDetModelo)\n","\n","    # Busca el objeto del XML en la lista de objetos detectados por el Modelo\n","    # (para eso considera la ubicación y tipo de clase)\n","    for objXML in listObjsXML:\n","\n","        i = -1\n","        noEnc = True\n","        while noEnc and i < (len(auxlistObjsDetModelo)-1):         \n","          i = i + 1\n","          \n","          # calcula la Intersection over Union (IoU) de los boxes\n","          objIoU = calc_IoU( objXML[2], auxlistObjsDetModelo[i][2] )\n","\n","          # si el IoU es casi perfecto, considera que es el objeto\n","          #if objIoU > 0.90: \n","          #  noEnc = False\n","          #else:\n","           #  analiza si tiene algo de superposición y es de la misma clase\n","          noEnc = not((objIoU > 0.1) and (objXML[1] == auxlistObjsDetModelo[i][1]))\n","\n","        if noEnc:\n","\n","           # Si no se encuentra objeto con misma ubicación y clase del XML\n","          if muestraDetalleDebug:\n","              print(objXML[1], \" no detectado por el Modelo con misma ubicación y clase \")\n","\n","          # registra que ese objeto no se encontró\n","          resCompara.append(  (objXML[1], -1, objXML[2], \"*\") )\n","\n","        else:\n","\n","          # Si encuentra objecto en misma ubicación y  clase del XML\n","          if muestraDetalleDebug:\n","              print(objXML[1], \": \", objIoU)\n","\n","          # regista que el objeto se encontró con su IoU\n","          resCompara.append(  (objXML[1], objIoU, auxlistObjsDetModelo[i][2], auxlistObjsDetModelo[i][1]) )\n","\n","          # saca el objeto de la lista auxiliar para que no se vuelva a usar\n","          auxlistObjsDetModelo.pop(i)\n","\n","    # Revisa los objetos detectados que no se utilizaron en la comparación anterior\n","    # para incluir en la comparación  \n","    #  objetos en la misma ubicación pero  con distinta clase\n","    #   u objetos detectados que no figuran en el XML\n","    if len(auxlistObjsDetModelo) > 0:\n","      if muestraDetalleDebug:\n","        print(\"\\n-Se intenta asociar con \", len(auxlistObjsDetModelo), \" objetos detectados del Modelo no utilizados\")\n","\n","      for objDet in auxlistObjsDetModelo:\n","\n","        # lo compara con los que no se puedieron detectar\n","        i = 0\n","        cont = True\n","        while cont and i < len(resCompara):\n","\n","            # sólo procesa es un objeto del XML no encontrado en Modelo \n","            if (resCompara[i][1] < 0):\n","                # calcula la Intersection over Union (IoU) de los boxes\n","                objIoU = calc_IoU( resCompara[i][2], objDet[2] )\n","\n","                if objIoU >= coefIoU:\n","                      # si están superpuestos se considera que se detectó pero le asignó mal la clase                    \n","                      resCompara[i] = (resCompara[i][0], objIoU, objDet[2], objDet[1] )                   \n","                      cont = False\n","\n","                      if muestraDetalleDebug:\n","                          print(\"--- Se rectifica objeto no detectado: \", resCompara[i])\n","            i = i + 1\n","\n","        if cont:\n","          # si no se utiliza, se agrega como objeto detectado de más\n","          resCompara.append(  (\"*\", 999, objDet[2], objDet[1]) )\n","\n","          if muestraDetalleDebug:\n","              print(\"--- Se agrega objeto detectado por Modelo de más: \", objDet[1])\n","\n","    if muestraDetalleDebug:\n","\n","        print(\"\\n+ Resultados de la Comparación:\")\n","        print( len(resCompara), \" : \", resCompara )\n","\n","\n","    # Realiza el cálculo de las Métricas de la Imagen considerando los resultados de la comparación\n","    ## ---------------------------------------------------------------------------------------------\n","    ## Nota los Verdadero Negativo (VN) se deberían calcular considerando el resto de la imagen que no tiene \n","    ## objetos, por lo que no es útil para Modelos de Object Detection y no se utiliza.\n","    ## ---------------------------------------------------------------------------------------------\n","    metricasImag = [ 0, 0, 0, 0]\n","\n","    hayErrorDetectado = False\n","    generaImagenComparacion = (muestraDetalleComparacionEnImagen != \"Ninguna\")\n","    if generaImagenComparacion:\n","      # imagen auxiliar para mostrar resultados comparación\n","      comp_image_pil = copy.deepcopy(imageCargada.convert(\"RGB\"))\n","      comp_draw = ImageDraw.Draw(comp_image_pil)\n","      im_width, im_height = comp_image_pil.size     \n","\n","    for resObj in resCompara:\n","\n","        if generaImagenComparacion:\n","          # agrega en vectores auxiliares para hacer la evaluación por clase\n","          classObjReal.append( resObj[0] )\n","          classObjModelo.append( resObj[3] )\n","\n","        if (resObj[0] == resObj[3]) and (resObj[1] >= coefIoU):\n","\n","            # Objeto de misma Clase entre XML y Modelo con IoU ≥ coefIoU -> Verdadero Positivo (VP)\n","            posM = posVP\n","            if generaImagenComparacion:            \n","              draw_box(comp_draw, resObj[2], 4, (0,255,0)) # cuadros Verdes\n","\n","        elif resObj[1] < 0:\n","\n","            # Objecto del XML no encontrado en Modelo -> Falso Negativo (FN)\n","            posM = posFN\n","            hayErrorDetectado = True\n","            if generaImagenComparacion:\n","              draw_box(comp_draw, resObj[2], 4, (255,0,0)) # cuadros Rojos\n","\n","        else:\n","\n","            # Objeto de misma Clase entre XML y Modelo con calc_IoU(r1, r2) < coefIoU -> Falso Positivo (FP)\n","            # Objeto de distinta Clase entre XML y Modelo con calc_IoU(r1, r2) ≥ coefIoU -> Falso Positivo (FP)\n","            # Objeto detectado por el Modelo que no aparece en el Modelo -> Falso Positivo (FP)\n","            posM = posFP\n","            hayErrorDetectado = True\n","            if generaImagenComparacion:            \n","              if resObj[1] == 999:\n","                draw_box(comp_draw, resObj[2], 4, (255,155,255)) # cuadros Rosa\n","              elif (resObj[0] != resObj[3]):\n","                draw_box(comp_draw, resObj[2], 4, (255,255,0)) # cuadros Amarillo\n","              else:\n","                draw_box(comp_draw, resObj[2], 4, (255,155,0)) # cuadros Naranja\n","\n","        metricasImag[posM] = metricasImag[posM] + 1\n","\n","    # Agrega a la métrica general\n","    for i in range(4):\n","      metricasGral[i] = metricasGral[i] + metricasImag[i]\n","\n","    if generaImagenComparacion and ( (muestraDetalleComparacionEnImagen == \"Todas\") or ( hayErrorDetectado and (muestraDetalleComparacionEnImagen == \"Solo con Error\") ) ):\n","\n","        imMostrar = ImPIL.fromarray(np.array(comp_image_pil), 'RGB')\n","        display( imMostrar )\n","        print(\" Nota colores:\")\n","        print(\"     Verdaderos Positivos (igual ubicación y misma clase): cuadros en VERDE.\")\n","        print(\"     Falsos Positivos (misma ubicación y distinta clase): cuadro en  AMARILLO\")\n","        print(\"     Falsos Positivos (diferencia de ubicación y misma clase): cuadros en NARANJA\")\n","        print(\"     Falsos Positivos (detectados de más por el Modelo): cuadros en ROSA \")        \n","        print(\"     Falsos Negativos (no detectado por el Modelo): cuadros en ROJO.\")\n","\n","    if ( (muestraDetalleMetricasPorImagen == \"Todas\") or ( hayErrorDetectado and (muestraDetalleMetricasPorImagen == \"Solo con Error\") ) ):\n","        print(\"\\n= Matriz de Confusión para la Imagen:\")        \n","        print(\"                  Modelo \")\n","        print(\" XML   :       +          -   \")\n","        print(\"  +    :     %3d        %3d  \" % (metricasImag[posVP], metricasImag[posFN]) )\n","        print(\"  -    :     %3d        %3d  \" % (metricasImag[posFP], metricasImag[posVN]) )\n","\n","        # Cálculo de la Exactitud\n","        total = (metricasImag[posVP] + metricasImag[posFP] + metricasImag[posVN] + metricasImag[posFN])\n","        if total>0:\n","            print(\"= Exactitud: \", round(100*(metricasImag[posVP] + metricasImag[posVN])/total, 3))\n","\n","        # Cálculo de la Precisión\n","        total = (metricasImag[posVP] + metricasImag[posFP])\n","        if total>0:\n","            print(\"= Precisión: \",  round(100*metricasImag[posVP]/total,3))\n","\n","        # Cálculo de la Recuperación\n","        total = (metricasImag[posVP] + metricasImag[posFN])\n","        if total>0:\n","            print(\"= Recuperación: \", round(100*metricasImag[posVP]/total,3))\n","    \n","    else:\n","\n","        if hayErrorDetectado: \n","            print(\" -- se detecta al menos un error!\")\n","        else:\n","            print(\" ++ sin error detectado.\")\n","        \n","# Muestra las Métricas Generales\n","print(\"\\n\\n===========================================================================================================\")\n","\n","print(\"\\n= Matriz de Confusión General del Modelo Entrenado:\")        \n","print(\"                  Modelo \")\n","print(\" XML   :       +          -   \")\n","print(\"  +    :     %3d        %3d  \" % (metricasGral[posVP], metricasGral[posFN]) )\n","print(\"  -    :     %3d        %3d  \" % (metricasGral[posFP], metricasGral[posVN]) )\n","\n","# Cálculo de la Exactitud\n","total = (metricasGral[posVP] + metricasGral[posFP] + metricasGral[posVN] + metricasGral[posFN])\n","if total>0:\n","    print(\"= Exactitud: \", round(100*(metricasGral[posVP] + metricasGral[posVN])/total, 3))\n","\n","# Cálculo de la Precisión\n","total = (metricasGral[posVP] + metricasGral[posFP])\n","if total>0:\n","    print(\"= Precisión: \",  round(100*metricasGral[posVP]/total,3))\n","\n","# Cálculo de la Recuperación\n","total = (metricasGral[posVP] + metricasGral[posFN])\n","if total>0:\n","    print(\"= Recuperación: \", round(100*metricasGral[posVP]/total,3))\n","\n","print(\"\\n===========================================================================================================\\n\")\n","\n","# muestra la evaluación por clase\n","if muestraDetalleMetricasPorClaseObjeto:\n","\n","    # muestra reporte de clasificación\n","    print(\"\\n Reporte de Clasificación por Clase del Modelo Entrenado: \")\n","    print(classification_report(y_true=classObjReal, y_pred=classObjModelo))\n","\n","\n","    pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n","\n","    # muestra matriz de confusion\n","    print('\\nMatriz de Confusión por Clase del Modelo Entrenado: ')\n","    CLASSES = list(set(classObjReal + classObjModelo))    \n","    cm = confusion_matrix(y_true=classObjReal, y_pred=classObjModelo, labels=CLASSES)\n","    cmtx = pd.DataFrame(\n","        cm, \n","        index=['r:{:}'.format(x) for x in CLASSES], \n","        columns=['m:{:}'.format(x) for x in CLASSES]\n","      )\n","    print(cmtx)\n","\n","    print(\"\\n===========================================================================================================\\n\")\n"],"execution_count":null,"outputs":[]}]}